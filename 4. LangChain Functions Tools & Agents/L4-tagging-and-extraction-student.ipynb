{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16de7336",
   "metadata": {},
   "source": [
    "# Tagging and Extraction Using OpenAI functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfb2ede9-b0b4-4c8c-b00f-9a9911f38614",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "from typing import List\n",
    "from pydantic import BaseModel, Field\n",
    "from langchain.utils.openai_functions import convert_pydantic_to_openai_function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b3ae5481-4155-4831-a5dd-4c183b3b4990",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "class Tagging(BaseModel):\n",
    "    \"\"\"Tag the piece of text with particular info.\"\"\"\n",
    "    sentiment: str = Field(description=\"sentiment of text, should be `pos`, `neg`, or `neutral`\")\n",
    "    language: str = Field(description=\"language of text (should be ISO 639-1 code)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3cd656b2-62be-49d4-a277-b920c67203c1",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kaila\\DLAI\\lib\\site-packages\\langchain_core\\_api\\deprecation.py:119: LangChainDeprecationWarning: The function `convert_pydantic_to_openai_function` was deprecated in LangChain 0.1.16 and will be removed in 0.2.0. Use langchain_core.utils.function_calling.convert_to_openai_function() instead.\n",
      "  warn_deprecated(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'name': 'Tagging',\n",
       " 'description': 'Tag the piece of text with particular info.',\n",
       " 'parameters': {'properties': {'sentiment': {'description': 'sentiment of text, should be `pos`, `neg`, or `neutral`',\n",
       "    'type': 'string'},\n",
       "   'language': {'description': 'language of text (should be ISO 639-1 code)',\n",
       "    'type': 'string'}},\n",
       "  'required': ['sentiment', 'language'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_pydantic_to_openai_function(Tagging)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed8b15a7-450c-43d6-af44-ca63800a4619",
   "metadata": {
    "height": 48
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "from langchain.chat_models import ChatOllama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2cc5bac3-3783-4ce7-9de6-83c905fba7c5",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "model = ChatOllama(model=\"zephyr:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "798ac5b3-7e47-4cfb-8173-63900cf1e7f6",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "tagging_functions = [convert_pydantic_to_openai_function(Tagging)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d558031-18cf-4791-b061-8911ce314605",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Think carefully, and then tag the text as instructed\"),\n",
    "    (\"user\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "00607aff-a64e-42b7-8cf4-893e8393dd33",
   "metadata": {
    "height": 82
   },
   "outputs": [],
   "source": [
    "model_with_functions = model.bind(\n",
    "    functions=tagging_functions,\n",
    "    function_call={\"name\": \"Tagging\"}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1d0bc519-2b8e-40d0-88ec-fc5ef0291f16",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "tagging_chain = prompt | model_with_functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8688fdba-0996-446c-a77b-318094944998",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='You can tag this text as \"personal opinion\" or \"user statement\". The choice depends on the context in which it is used. If it appears in a discussion about language processing libraries, then \"personal opinion\" would be appropriate. However, if it is part of a product review, then \"user statement\" might be more relevant. In either case, both tags are useful for categorizing and searching through content, making it easier to find similar opinions or statements in the future.' response_metadata={'model': 'zephyr:latest', 'created_at': '2024-06-02T13:36:43.9190875Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 54836821800, 'load_duration': 16509561800, 'prompt_eval_count': 46, 'prompt_eval_duration': 3291710000, 'eval_count': 98, 'eval_duration': 35012875000} id='run-189d7b9b-6329-4db0-adbd-ce4acebad876-0'\n"
     ]
    }
   ],
   "source": [
    "print(tagging_chain.invoke({\"input\": \"I love langchain\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7df9aac5-7194-4a12-bda7-e7e83e705929",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "content='Tag: personal preference (dislike)\\nText: non mi piace questo cibo\\nExplanation: \"non mi piace questo cibo\" translates to \"I do not like this food.\" This is a statement of personal preference, indicating that the author does not enjoy the specific food being referred to.' response_metadata={'model': 'zephyr:latest', 'created_at': '2024-06-02T13:38:32.4257693Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 28915694600, 'load_duration': 4558400, 'prompt_eval_count': 19, 'prompt_eval_duration': 2494493000, 'eval_count': 68, 'eval_duration': 26413098000} id='run-432e3ca8-4c04-4d15-ab2e-09b447fe693f-0'\n"
     ]
    }
   ],
   "source": [
    "print(tagging_chain.invoke({\"input\": \"non mi piace questo cibo\"}))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92e417b4-9306-413f-865f-e13dbd2d0196",
   "metadata": {},
   "source": [
    "## Extraction\n",
    "\n",
    "Extraction is similar to tagging, but used for extracting multiple pieces of information."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "97338dce-a61a-4f8b-912c-6108dcb86183",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "class Person(BaseModel):\n",
    "    \"\"\"Information about a person.\"\"\"\n",
    "    name: str = Field(description=\"person's name\")\n",
    "    age: Optional[int] = Field(description=\"person's age\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f558fb45-f3a5-47be-8778-dddec2d00ba1",
   "metadata": {
    "height": 81
   },
   "outputs": [],
   "source": [
    "class Information(BaseModel):\n",
    "    \"\"\"Information to extract.\"\"\"\n",
    "    people: List[Person] = Field(description=\"List of info about people\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5eeb6028-0ade-46f6-a899-ca10f185bb24",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Information',\n",
       " 'description': 'Information to extract.',\n",
       " 'parameters': {'$defs': {'Person': {'description': 'Information about a person.',\n",
       "    'properties': {'name': {'description': \"person's name\", 'type': 'string'},\n",
       "     'age': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "      'description': \"person's age\"}},\n",
       "    'required': ['name', 'age'],\n",
       "    'type': 'object'}},\n",
       "  'properties': {'people': {'description': 'List of info about people',\n",
       "    'items': {'description': 'Information about a person.',\n",
       "     'properties': {'name': {'description': \"person's name\", 'type': 'string'},\n",
       "      'age': {'anyOf': [{'type': 'integer'}, {'type': 'null'}],\n",
       "       'description': \"person's age\"}},\n",
       "     'required': ['name', 'age'],\n",
       "     'type': 'object'},\n",
       "    'type': 'array'}},\n",
       "  'required': ['people'],\n",
       "  'type': 'object'}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "convert_pydantic_to_openai_function(Information)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f16ce50e-bad7-4fbb-b9e2-0adae6fc55f2",
   "metadata": {
    "height": 64
   },
   "outputs": [],
   "source": [
    "extraction_functions = [convert_pydantic_to_openai_function(Information)]\n",
    "extraction_model = model.bind(functions=extraction_functions, function_call={\"name\": \"Information\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3ed58069-3f7c-433e-93ed-5660d21435c9",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"And Joe's grandmother is Martha's mother, making Joe's grandmother one generation older than Joe's mother. Therefore, Joe's grandmother is also related to Joe, but in a different way - she is Joe's maternal grandmother. So Joe's relationship with his grandmother is that of a grandson, while his mother's relationship with her mother is that of a daughter.\\n\\nIn summary:\\n- Joe's mother (Martha) is 30 years old\\n- Martha's mother is Joe's grandmother\\n- Joe's relationship with his grandmother is grandson, as his grandmother is one generation older than his mom and related to him through his mom (Joe's maternal grandmother)\", response_metadata={'model': 'zephyr:latest', 'created_at': '2024-06-02T13:40:38.6059775Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 75602011100, 'load_duration': 5864600, 'prompt_eval_count': 26, 'prompt_eval_duration': 3079610000, 'eval_count': 155, 'eval_duration': 72512877000}, id='run-c118123f-d7a4-4668-b008-a4d2a6b98bfd-0')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_model.invoke(\"Joe is 30, his mom is Martha\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "172df097-250a-4813-b76d-21436c13056d",
   "metadata": {
    "height": 98
   },
   "outputs": [],
   "source": [
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", \"Extract the relevant information, if not explicitly provided do not guess. Extract partial info\"),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dfec48d7-25a2-46d7-a7a2-33284b577dd3",
   "metadata": {
    "height": 31
   },
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f19622af-4b01-4145-ae5a-af15b551a182",
   "metadata": {
    "height": 47
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Relevant information: Joe's name is Joe and his mother's name is Martha. Both individuals have their own ages, but without further information it cannot be determined how old either of them are.\", response_metadata={'model': 'zephyr:latest', 'created_at': '2024-06-02T13:41:03.628908Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 22840324500, 'load_duration': 4198400, 'prompt_eval_count': 53, 'prompt_eval_duration': 3639059000, 'eval_count': 43, 'eval_duration': 19188615000}, id='run-14d61d97-5992-4db9-bc95-fcdd82b74145-0')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": \"Joe is 30, his mom is Martha\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9db0d107-5284-4253-b769-dfedb97ce95d",
   "metadata": {
    "height": 115
   },
   "outputs": [],
   "source": [
    "class Overview(BaseModel):\n",
    "    \"\"\"Overview of a section of text.\"\"\"\n",
    "    summary: str = Field(description=\"Provide a concise summary of the content.\")\n",
    "    language: str = Field(description=\"Provide the language that the content is written in.\")\n",
    "    keywords: str = Field(description=\"Provide keywords related to the content.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6bfe7fe6-a86d-416c-a7f2-373dc70fcba5",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "overview_tagging_function = [\n",
    "    convert_pydantic_to_openai_function(Overview)\n",
    "]\n",
    "tagging_model = model.bind(\n",
    "    functions=overview_tagging_function,\n",
    "    function_call={\"name\":\"Overview\"}\n",
    ")\n",
    "tagging_chain = prompt | tagging_model | JsonOutputFunctionsParser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "518f2337-a8eb-4eff-b764-b70e48545d19",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'summary': 'This text discusses the concept of building autonomous agents powered by LLM (large language model) as the core controller. It covers components such as planning, memory, and tool use, along with examples and challenges in implementing LLM-powered agents.',\n",
       " 'language': 'English',\n",
       " 'keywords': 'LLM, autonomous agents, planning, memory, tool use, proof-of-concepts, challenges'}"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagging_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5be5d604-3d95-476a-afe4-b46b021534fc",
   "metadata": {
    "height": 167
   },
   "outputs": [],
   "source": [
    "class Paper(BaseModel):\n",
    "    \"\"\"Information about papers mentioned.\"\"\"\n",
    "    title: str\n",
    "    author: Optional[str]\n",
    "\n",
    "\n",
    "class Info(BaseModel):\n",
    "    \"\"\"Information to extract\"\"\"\n",
    "    papers: List[Paper]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8e56ca98-d05d-4199-a6ec-fe485b630da6",
   "metadata": {
    "height": 166
   },
   "outputs": [],
   "source": [
    "paper_extraction_function = [\n",
    "    convert_pydantic_to_openai_function(Info)\n",
    "]\n",
    "extraction_model = model.bind(\n",
    "    functions=paper_extraction_function, \n",
    "    function_call={\"name\":\"Info\"}\n",
    ")\n",
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f082b7a0-b7ea-488a-923c-aba8e4b185a0",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'LLM Powered Autonomous Agents', 'author': 'Lilian Weng'}]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "2a8dcce7-7032-49a8-893d-1659e2f51f03",
   "metadata": {
    "height": 200
   },
   "outputs": [],
   "source": [
    "template = \"\"\"A article will be passed to you. Extract from it all papers that are mentioned by this article. \n",
    "\n",
    "Do not extract the name of the article itself. If no papers are mentioned that's fine - you don't need to extract any! Just return an empty list.\n",
    "\n",
    "Do not make up or guess ANY extra information. Only extract what exactly is in the text.\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages([\n",
    "    (\"system\", template),\n",
    "    (\"human\", \"{input}\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a5f4c8cc-d9a4-4556-a89e-94ec981c6f5e",
   "metadata": {
    "height": 47
   },
   "outputs": [],
   "source": [
    "extraction_chain = prompt | extraction_model | JsonKeyOutputFunctionsParser(key_name=\"papers\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b63e00b6-0f06-4e74-948e-04805e66f40c",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'Chain of thought (CoT; Wei et al. 2022)'},\n",
       " {'title': 'Tree of Thoughts (Yao et al. 2023)'},\n",
       " {'title': 'LLM+P (Liu et al. 2023)'},\n",
       " {'title': 'ReAct (Yao et al. 2023)'},\n",
       " {'title': 'Reflexion (Shinn & Labash 2023)'},\n",
       " {'title': 'Chain of Hindsight (CoH; Liu et al. 2023)'},\n",
       " {'title': 'Algorithm Distillation (AD; Laskin et al. 2023)'}]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": page_content})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "365bfa5b-f0d2-4a19-8db1-1b4a0f51703d",
   "metadata": {
    "height": 31
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extraction_chain.invoke({\"input\": \"hi\"})"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
