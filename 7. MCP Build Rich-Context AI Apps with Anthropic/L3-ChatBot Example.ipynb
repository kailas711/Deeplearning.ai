{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c10b768-f5b4-43bc-a785-99077422ce78",
   "metadata": {},
   "source": [
    "# Lesson 3: Chatbot Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d4fedc-4b90-4754-9f2d-fd3cfa321a14",
   "metadata": {},
   "source": [
    "In this lesson, you will familiarize yourself with the chatbot example you will work on during this course. The example includes the tool definitions and execution, as well as the chatbot code. Make sure to interact with the chatbot at the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ed96ba-5ade-4af4-9096-406ce48d5cf2",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd6bd1d4-f652-45d1-9efa-155a2cc01713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20f163a-87af-4e0c-87ed-1624c150c572",
   "metadata": {},
   "source": [
    "## Tool Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "549a7f46-74b3-4a1d-b084-055c99e3c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_DIR = \"papers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e43905e-56f3-404c-a322-f038055e9b1c",
   "metadata": {},
   "source": [
    "The first tool searches for relevant arXiv papers based on a topic and stores the papers' info in a JSON file (title, authors, summary, paper url and the publication date). The JSON files are organized by topics in the `papers` directory. The tool does not download the papers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "886633b8-ce67-4343-822d-cc3f98f953fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use arxiv to find the papers \n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "    \n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info  \n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "    \n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "    \n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "    \n",
    "    return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d20ee17a-afe6-438a-95b1-6e87742c7fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers\\rag_pipelines\\papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2506.09542v1',\n",
       " '2501.15228v1',\n",
       " '2504.13587v1',\n",
       " '2409.19019v1',\n",
       " '2506.08364v2']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_papers(\"RAG pipelines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb83565-69af-47f3-9ba3-a96965cff7df",
   "metadata": {},
   "source": [
    "The second tool looks for information about a specific paper across all topic directories inside the `papers` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df9b1997-81cd-447d-9665-1cb72d93bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    " \n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return f\"There's no saved information related to paper {paper_id}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0ebe0de7-8f07-4e08-a670-7b371fc3d2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"title\": \"KG-Infused RAG: Augmenting Corpus-Based RAG with External Knowledge Graphs\",\\n  \"authors\": [\\n    \"Dingjun Wu\",\\n    \"Yukun Yan\",\\n    \"Zhenghao Liu\",\\n    \"Zhiyuan Liu\",\\n    \"Maosong Sun\"\\n  ],\\n  \"summary\": \"Retrieval-Augmented Generation (RAG) improves factual accuracy by grounding\\\\nresponses in external knowledge. However, existing methods typically rely on a\\\\nsingle source, either unstructured text or structured knowledge. Moreover, they\\\\nlack cognitively inspired mechanisms for activating relevant knowledge. To\\\\naddress these issues, we propose KG-Infused RAG, a framework that integrates\\\\nKGs into RAG systems to implement spreading activation, a cognitive process\\\\nthat enables concept association and inference. KG-Infused RAG retrieves KG\\\\nfacts, expands the query accordingly, and enhances generation by combining\\\\ncorpus passages with structured facts, enabling interpretable, multi-source\\\\nretrieval grounded in semantic structure. We further improve KG-Infused RAG via\\\\npreference learning on sampled key stages in the pipeline. Experiments on five\\\\nQA benchmarks show that KG-Infused RAG consistently outperforms vanilla RAG (by\\\\n3.8% to 13.8%). Additionally, when integrated into Self-RAG, KG-Infused RAG\\\\nbrings further performance gains, demonstrating its effectiveness and\\\\nversatility as a plug-and-play enhancement module for corpus-based RAG methods.\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/2506.09542v1\",\\n  \"published\": \"2025-06-11\"\\n}'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_info('2506.09542v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea3013-e690-4bc8-8622-27b4d42d61e4",
   "metadata": {},
   "source": [
    "## Tool Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d2260-452d-472a-b56e-326479cb18c9",
   "metadata": {},
   "source": [
    "Here are the schema of each tool which you will provide to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d64ad21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(model='smollm2:360m', modified_at=datetime.datetime(2025, 7, 20, 20, 33, 57, 246020, tzinfo=TzInfo(+05:30)), digest='297281b699fc51376006233ca400cd664c4f7b80ed88a47ef084f1e4b089803b', size=725566512, details=ModelDetails(parent_model='', format='gguf', family='llama', families=['llama'], parameter_size='361.82M', quantization_level='F16')),\n",
       " Model(model='deepseek-r1:1.5b', modified_at=datetime.datetime(2025, 7, 20, 14, 30, 5, 38801, tzinfo=TzInfo(+05:30)), digest='e0979632db5a88d1a53884cb2a941772d10ff5d055aabaa6801c4e36f3a6c2d7', size=1117322768, details=ModelDetails(parent_model='', format='gguf', family='qwen2', families=['qwen2'], parameter_size='1.8B', quantization_level='Q4_K_M')),\n",
       " Model(model='qwen3:0.6b', modified_at=datetime.datetime(2025, 7, 18, 8, 56, 17, 833106, tzinfo=TzInfo(+05:30)), digest='7df6b6e09427a769808717c0a93cadc4ae99ed4eb8bf5ca557c90846becea435', size=522653767, details=ModelDetails(parent_model='', format='gguf', family='qwen3', families=['qwen3'], parameter_size='751.63M', quantization_level='Q4_K_M')),\n",
       " Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 6, 18, 0, 35, 9, 741285, tzinfo=TzInfo(+05:30)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M')),\n",
       " Model(model='qwen3:1.7b', modified_at=datetime.datetime(2025, 6, 13, 0, 0, 55, 230752, tzinfo=TzInfo(+05:30)), digest='8f68893c685c3ddff2aa3fffce2aa60a30bb2da65ca488b61fff134a4d1730e7', size=1359293444, details=ModelDetails(parent_model='', format='gguf', family='qwen3', families=['qwen3'], parameter_size='2.0B', quantization_level='Q4_K_M'))]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "ollama.list().models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "39da837e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ollama import Client\n",
    "client = Client(\n",
    "  host='http://localhost:11434',\n",
    ")\n",
    "response = client.chat(model='qwen3:1.7b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'Why is the sky blue?',\n",
    "  },\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0af714c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ResponseError",
     "evalue": "registry.ollama.ai/library/smollm2:360m does not support tools (status code: 400)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mResponseError\u001b[39m                             Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43msmollm2:360m\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mWhat is the weather in Toronto?\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m      5\u001b[39m \n\u001b[32m      6\u001b[39m \u001b[43m\t\t\u001b[49m\u001b[38;5;66;43;03m# provide a weather checking tool to the model\u001b[39;49;00m\n\u001b[32m      7\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m      \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfunction\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m      \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mfunction\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mname\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mget_current_weather\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdescription\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mGet the current weather for a city\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mparameters\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mobject\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mproperties\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m            \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcity\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m              \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mtype\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mstring\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     17\u001b[39m \u001b[43m              \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdescription\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mThe name of the city\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     18\u001b[39m \u001b[43m            \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     19\u001b[39m \u001b[43m          \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     20\u001b[39m \u001b[43m          \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrequired\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcity\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     21\u001b[39m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     22\u001b[39m \u001b[43m      \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     23\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     24\u001b[39m \u001b[43m  \u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     25\u001b[39m \u001b[43m)\u001b[49m\n\u001b[32m     27\u001b[39m \u001b[38;5;28mprint\u001b[39m(response[\u001b[33m'\u001b[39m\u001b[33mmessage\u001b[39m\u001b[33m'\u001b[39m][\u001b[33m'\u001b[39m\u001b[33mtool_calls\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\ollama\\_client.py:333\u001b[39m, in \u001b[36mClient.chat\u001b[39m\u001b[34m(self, model, messages, tools, stream, format, options, keep_alive)\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat\u001b[39m(\n\u001b[32m    290\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    291\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    298\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    299\u001b[39m ) -> Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[32m    300\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    301\u001b[39m \u001b[33;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[32m    302\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    331\u001b[39m \u001b[33;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/chat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\ollama\\_client.py:178\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    176\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\ollama\\_client.py:122\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    120\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m r\n\u001b[32m    121\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.HTTPStatusError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m122\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m ResponseError(e.response.text, e.response.status_code) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    123\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m httpx.ConnectError:\n\u001b[32m    124\u001b[39m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(CONNECTION_ERROR_MESSAGE) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mResponseError\u001b[39m: registry.ollama.ai/library/smollm2:360m does not support tools (status code: 400)"
     ]
    }
   ],
   "source": [
    "response = client.chat(\n",
    "    model='smollm2:360m',\n",
    "    messages=[{'role': 'user', 'content':\n",
    "        'What is the weather in Toronto?'}],\n",
    "\n",
    "\t\t# provide a weather checking tool to the model\n",
    "    tools=[{\n",
    "      'type': 'function',\n",
    "      'function': {\n",
    "        'name': 'get_current_weather',\n",
    "        'description': 'Get the current weather for a city',\n",
    "        'parameters': {\n",
    "          'type': 'object',\n",
    "          'properties': {\n",
    "            'city': {\n",
    "              'type': 'string',\n",
    "              'description': 'The name of the city',\n",
    "            },\n",
    "          },\n",
    "          'required': ['city'],\n",
    "        },\n",
    "      },\n",
    "    },\n",
    "  ],\n",
    ")\n",
    "\n",
    "print(response['message']['tool_calls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5bdea5f-e93a-4018-8c13-00d5ee10c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"name\": \"search_papers\",\n",
    "        \"description\": \"This tool search for papers on arXiv based on a topic and store their information.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"topic\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The topic to search for\"\n",
    "                }, \n",
    "                \"max_results\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Maximum number of results to retrieve\",\n",
    "                    \"default\": 5\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"topic\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "      'type': 'function',\n",
    "      'function': {\n",
    "        'name': 'get_current_weather',\n",
    "        'description': 'Get the current weather for a city',\n",
    "        'parameters': {\n",
    "          'type': 'object',\n",
    "          'properties': {\n",
    "            'city': {\n",
    "              'type': 'string',\n",
    "              'description': 'The name of the city',\n",
    "            },\n",
    "          },\n",
    "          'required': ['city'],\n",
    "        },\n",
    "      },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec668d24-1559-41b7-bc8a-e2dca77dfaf2",
   "metadata": {},
   "source": [
    "## Tool Mapping\n",
    "\n",
    "```\n",
    "    {\n",
    "        \"name\": \"extract_info\",\n",
    "        \"description\": \"This tool search for information about a specific paper across all topic directories.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"paper_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The ID of the paper to look for\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"paper_id\"]\n",
    "        }\n",
    "    },\n",
    "\n",
    "    ```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c728c1ec-36b1-48b4-9f85-622464ac79f4",
   "metadata": {},
   "source": [
    "This code handles tool mapping and execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c90790c0-efc4-4068-9c00-d2592d80bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info\n",
    "}\n",
    "\n",
    "def execute_tool(tool_name, tool_args):\n",
    "    \n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "\n",
    "    if result is None:\n",
    "        result = \"The operation completed but didn't return any results.\"\n",
    "        \n",
    "    elif isinstance(result, list):\n",
    "        result = ', '.join(result)\n",
    "        \n",
    "    elif isinstance(result, dict):\n",
    "        # Convert dictionaries to formatted JSON strings\n",
    "        result = json.dumps(result, indent=2)\n",
    "    \n",
    "    else:\n",
    "        # For any other type, convert using str()\n",
    "        result = str(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3f38ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'search_papers',\n",
       "  'description': 'This tool search for papers on arXiv based on a topic and store their information.',\n",
       "  'input_schema': {'type': 'object',\n",
       "   'properties': {'topic': {'type': 'string',\n",
       "     'description': 'The topic to search for'},\n",
       "    'max_results': {'type': 'integer',\n",
       "     'description': 'Maximum number of results to retrieve',\n",
       "     'default': 5}},\n",
       "   'required': ['topic']}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'get_current_weather',\n",
       "   'description': 'Get the current weather for a city',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'city': {'type': 'string',\n",
       "      'description': 'The name of the city'}},\n",
       "    'required': ['city']}}}]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8fc4d3-58ac-482c-8bbd-bccd6ef9fc31",
   "metadata": {},
   "source": [
    "## Chatbot Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba0fad-b0e4-4415-a431-341e9ca85087",
   "metadata": {},
   "source": [
    "The chatbot handles the user's queries one by one, but it does not persist memory across the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "fe662400-8506-464e-a3da-75a3d8848bac",
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadError",
     "evalue": "[WinError 10054] An existing connection was forcibly closed by the remote host",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mReadError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\httpx\\_transports\\default.py:101\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    100\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m101\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    102\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\httpx\\_transports\\default.py:250\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    249\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[32m--> \u001b[39m\u001b[32m250\u001b[39m     resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:256\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    255\u001b[39m     \u001b[38;5;28mself\u001b[39m._close_connections(closing)\n\u001b[32m--> \u001b[39m\u001b[32m256\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m    258\u001b[39m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[32m    259\u001b[39m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:236\u001b[39m, in \u001b[36mConnectionPool.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    234\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    235\u001b[39m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m236\u001b[39m     response = \u001b[43mconnection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    237\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\n\u001b[32m    238\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    239\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[32m    240\u001b[39m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[32m    241\u001b[39m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[32m    242\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    243\u001b[39m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\httpcore\\_sync\\connection.py:103\u001b[39m, in \u001b[36mHTTPConnection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    101\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[32m--> \u001b[39m\u001b[32m103\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_connection\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\httpcore\\_sync\\http11.py:136\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    135\u001b[39m         \u001b[38;5;28mself\u001b[39m._response_closed()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m exc\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\httpcore\\_sync\\http11.py:106\u001b[39m, in \u001b[36mHTTP11Connection.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\n\u001b[32m     98\u001b[39m     \u001b[33m\"\u001b[39m\u001b[33mreceive_response_headers\u001b[39m\u001b[33m\"\u001b[39m, logger, request, kwargs\n\u001b[32m     99\u001b[39m ) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[32m    100\u001b[39m     (\n\u001b[32m    101\u001b[39m         http_version,\n\u001b[32m    102\u001b[39m         status,\n\u001b[32m    103\u001b[39m         reason_phrase,\n\u001b[32m    104\u001b[39m         headers,\n\u001b[32m    105\u001b[39m         trailing_data,\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m     ) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_response_headers\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m     trace.return_value = (\n\u001b[32m    108\u001b[39m         http_version,\n\u001b[32m    109\u001b[39m         status,\n\u001b[32m    110\u001b[39m         reason_phrase,\n\u001b[32m    111\u001b[39m         headers,\n\u001b[32m    112\u001b[39m     )\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\httpcore\\_sync\\http11.py:177\u001b[39m, in \u001b[36mHTTP11Connection._receive_response_headers\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    176\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m177\u001b[39m     event = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_receive_event\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(event, h11.Response):\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\httpcore\\_sync\\http11.py:217\u001b[39m, in \u001b[36mHTTP11Connection._receive_event\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    216\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m event \u001b[38;5;129;01mis\u001b[39;00m h11.NEED_DATA:\n\u001b[32m--> \u001b[39m\u001b[32m217\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_network_stream\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    218\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mREAD_NUM_BYTES\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\n\u001b[32m    219\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    221\u001b[39m     \u001b[38;5;66;03m# If we feed this case through h11 we'll raise an exception like:\u001b[39;00m\n\u001b[32m    222\u001b[39m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[32m    223\u001b[39m     \u001b[38;5;66;03m#     httpcore.RemoteProtocolError: can't handle event type\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    227\u001b[39m     \u001b[38;5;66;03m# perspective. Instead we handle this case distinctly and treat\u001b[39;00m\n\u001b[32m    228\u001b[39m     \u001b[38;5;66;03m# it as a ConnectError.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\httpcore\\_backends\\sync.py:126\u001b[39m, in \u001b[36mSyncStream.read\u001b[39m\u001b[34m(self, max_bytes, timeout)\u001b[39m\n\u001b[32m    125\u001b[39m exc_map: ExceptionMapping = {socket.timeout: ReadTimeout, \u001b[38;5;167;01mOSError\u001b[39;00m: ReadError}\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43msettimeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:155\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28mself\u001b[39m.gen.throw(typ, value, traceback)\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\httpcore\\_exceptions.py:14\u001b[39m, in \u001b[36mmap_exceptions\u001b[39m\u001b[34m(map)\u001b[39m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[32m---> \u001b[39m\u001b[32m14\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n\u001b[32m     15\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[31mReadError\u001b[39m: [WinError 10054] An existing connection was forcibly closed by the remote host",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[31mReadError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mollama\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[32m      4\u001b[39m client = Client(\n\u001b[32m      5\u001b[39m   host=\u001b[33m'\u001b[39m\u001b[33mhttp://localhost:11434\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      6\u001b[39m )\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m response = \u001b[43mclient\u001b[49m\u001b[43m.\u001b[49m\u001b[43mchat\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mqwen3:0.6b\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrole\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43muser\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mcontent\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m:\u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mwhat is the weather in bangalore\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m\t\t\u001b[49m\u001b[38;5;66;43;03m# provide a weather checking tool to the model\u001b[39;49;00m\n\u001b[32m     13\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtools\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\ollama\\_client.py:333\u001b[39m, in \u001b[36mClient.chat\u001b[39m\u001b[34m(self, model, messages, tools, stream, format, options, keep_alive)\u001b[39m\n\u001b[32m    289\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mchat\u001b[39m(\n\u001b[32m    290\u001b[39m   \u001b[38;5;28mself\u001b[39m,\n\u001b[32m    291\u001b[39m   model: \u001b[38;5;28mstr\u001b[39m = \u001b[33m'\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    298\u001b[39m   keep_alive: Optional[Union[\u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mstr\u001b[39m]] = \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[32m    299\u001b[39m ) -> Union[ChatResponse, Iterator[ChatResponse]]:\n\u001b[32m    300\u001b[39m \u001b[38;5;250m  \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    301\u001b[39m \u001b[33;03m  Create a chat response using the requested model.\u001b[39;00m\n\u001b[32m    302\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    331\u001b[39m \u001b[33;03m  Returns `ChatResponse` if `stream` is `False`, otherwise returns a `ChatResponse` generator.\u001b[39;00m\n\u001b[32m    332\u001b[39m \u001b[33;03m  \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m333\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mChatResponse\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    335\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mPOST\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    336\u001b[39m \u001b[43m    \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m/api/chat\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    337\u001b[39m \u001b[43m    \u001b[49m\u001b[43mjson\u001b[49m\u001b[43m=\u001b[49m\u001b[43mChatRequest\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    338\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    339\u001b[39m \u001b[43m      \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmessage\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_messages\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    340\u001b[39m \u001b[43m      \u001b[49m\u001b[43mtools\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtool\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m_copy_tools\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtools\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    341\u001b[39m \u001b[43m      \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    342\u001b[39m \u001b[43m      \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    343\u001b[39m \u001b[43m      \u001b[49m\u001b[43moptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    344\u001b[39m \u001b[43m      \u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkeep_alive\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    345\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmodel_dump\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexclude_none\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    346\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstream\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    347\u001b[39m \u001b[43m  \u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\ollama\\_client.py:178\u001b[39m, in \u001b[36mClient._request\u001b[39m\u001b[34m(self, cls, stream, *args, **kwargs)\u001b[39m\n\u001b[32m    174\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**part)\n\u001b[32m    176\u001b[39m   \u001b[38;5;28;01mreturn\u001b[39;00m inner()\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mcls\u001b[39m(**\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_request_raw\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m.json())\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\ollama\\_client.py:118\u001b[39m, in \u001b[36mClient._request_raw\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    116\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_request_raw\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m    117\u001b[39m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m     r = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_client\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    119\u001b[39m     r.raise_for_status()\n\u001b[32m    120\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m r\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\httpx\\_client.py:825\u001b[39m, in \u001b[36mClient.request\u001b[39m\u001b[34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[39m\n\u001b[32m    810\u001b[39m     warnings.warn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m, stacklevel=\u001b[32m2\u001b[39m)\n\u001b[32m    812\u001b[39m request = \u001b[38;5;28mself\u001b[39m.build_request(\n\u001b[32m    813\u001b[39m     method=method,\n\u001b[32m    814\u001b[39m     url=url,\n\u001b[32m   (...)\u001b[39m\u001b[32m    823\u001b[39m     extensions=extensions,\n\u001b[32m    824\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m825\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\httpx\\_client.py:914\u001b[39m, in \u001b[36mClient.send\u001b[39m\u001b[34m(self, request, stream, auth, follow_redirects)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;28mself\u001b[39m._set_timeout(request)\n\u001b[32m    912\u001b[39m auth = \u001b[38;5;28mself\u001b[39m._build_request_auth(request, auth)\n\u001b[32m--> \u001b[39m\u001b[32m914\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    915\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    916\u001b[39m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[43m=\u001b[49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    917\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    918\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    919\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    920\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    921\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\httpx\\_client.py:942\u001b[39m, in \u001b[36mClient._send_handling_auth\u001b[39m\u001b[34m(self, request, auth, follow_redirects, history)\u001b[39m\n\u001b[32m    939\u001b[39m request = \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[32m    941\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m942\u001b[39m     response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    943\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    944\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    945\u001b[39m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    946\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    947\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    948\u001b[39m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\httpx\\_client.py:979\u001b[39m, in \u001b[36mClient._send_handling_redirects\u001b[39m\u001b[34m(self, request, follow_redirects, history)\u001b[39m\n\u001b[32m    976\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mrequest\u001b[39m\u001b[33m\"\u001b[39m]:\n\u001b[32m    977\u001b[39m     hook(request)\n\u001b[32m--> \u001b[39m\u001b[32m979\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    980\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m    981\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._event_hooks[\u001b[33m\"\u001b[39m\u001b[33mresponse\u001b[39m\u001b[33m\"\u001b[39m]:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\httpx\\_client.py:1014\u001b[39m, in \u001b[36mClient._send_single_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m   1009\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m   1010\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1011\u001b[39m     )\n\u001b[32m   1013\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request=request):\n\u001b[32m-> \u001b[39m\u001b[32m1014\u001b[39m     response = \u001b[43mtransport\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response.stream, SyncByteStream)\n\u001b[32m   1018\u001b[39m response.request = request\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\httpx\\_transports\\default.py:249\u001b[39m, in \u001b[36mHTTPTransport.handle_request\u001b[39m\u001b[34m(self, request)\u001b[39m\n\u001b[32m    235\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhttpcore\u001b[39;00m\n\u001b[32m    237\u001b[39m req = httpcore.Request(\n\u001b[32m    238\u001b[39m     method=request.method,\n\u001b[32m    239\u001b[39m     url=httpcore.URL(\n\u001b[32m   (...)\u001b[39m\u001b[32m    247\u001b[39m     extensions=request.extensions,\n\u001b[32m    248\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m249\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m.\u001b[49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    252\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp.stream, typing.Iterable)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\contextlib.py:155\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    153\u001b[39m     value = typ()\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     \u001b[38;5;28mself\u001b[39m.gen.throw(typ, value, traceback)\n\u001b[32m    156\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    157\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    158\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    159\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[32m    160\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\kaila\\projects\\Lib\\site-packages\\httpx\\_transports\\default.py:118\u001b[39m, in \u001b[36mmap_httpcore_exceptions\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    115\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[32m    117\u001b[39m message = \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[32m--> \u001b[39m\u001b[32m118\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mexc\u001b[39;00m\n",
      "\u001b[31mReadError\u001b[39m: [WinError 10054] An existing connection was forcibly closed by the remote host"
     ]
    }
   ],
   "source": [
    "import ollama \n",
    "from ollama import Client\n",
    "\n",
    "client = Client(\n",
    "  host='http://localhost:11434',\n",
    ")\n",
    "\n",
    "response = client.chat(\n",
    "    model='qwen3:0.6b',\n",
    "    messages=[{'role': 'user', 'content':\n",
    "        'what is the weather in bangalore'}],\n",
    "\t\t# provide a weather checking tool to the model\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3ec314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user wants to search for a paper on mercury from Arxiv. Let me think about how to approach this.\n",
      "\n",
      "First, I need to recall the available tools. The user provided two empty functions, but maybe there's a way to use an external service. Since the functions are empty, perhaps I should use a web search or a specific API.\n",
      "\n",
      "Wait, the user mentioned Arxiv, so maybe the assistant can use a web search function. But the tools given are empty. Hmm. The assistant might not have the capability to perform web searches directly. Alternatively, maybe the assistant is supposed to use a predefined function for searching Arxiv.\n",
      "\n",
      "Wait, the tools section shows two functions with empty names and descriptions. That's confusing. Maybe the assistant is supposed to generate a search query based on the user's input. Since the user is asking for papers on mercury from Arxiv, the assistant could generate a search term like \"mercury\" and use a web search function.\n",
      "\n",
      "But the assistant's tools are empty, so perhaps it's not possible. However, the user might expect the assistant to use a known method. Alternatively, maybe the assistant should inform the user that it can't perform the search with the current tools. But the instructions say to call functions if possible.\n",
      "\n",
      "Wait, the assistant's tools are empty, so there's no function to call. But the user is asking for a search. Since the tools aren't set up, maybe the assistant can't perform the task. However, the assistant should respond by indicating that it can't help with that using the available tools. But the user might expect a different approach.\n",
      "\n",
      "Alternatively, maybe the assistant is supposed to generate a search query and return it. For example, the assistant could say \"Searching for papers on mercury from Arxiv...\" but without using any functions. However, the instructions say to call functions if possible. Since there are no functions, the assistant can't call any. So the correct response would be to inform the user that the assistant can't perform that task with the available tools.\n",
      "\n",
      "But the user might expect a different answer. Maybe the assistant should proceed to use a web search function even if the tools are empty. But since the tools are empty, the assistant can't. Therefore, the assistant should respond that it can't help with that request.\n",
      "</think>\n",
      "\n",
      "I cannot directly search Arxiv for papers, as my current capabilities are limited to the tools provided. However, I can guide you on how to find such papers:  \n",
      "1. Visit the [Arxiv website](https://arxiv.org/) and use the search bar.  \n",
      "2. Type \"mercury\" in the search box and press Enter.  \n",
      "3. Filter results by \"Paper\" type to find relevant academic articles.  \n",
      "\n",
      "Let me know if you need help with anything else!\n"
     ]
    }
   ],
   "source": [
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4cebc334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('role', 'assistant')\n",
      "('content', '<think>\\nOkay, the user wants to search for a paper on mercury from Arxiv. Let me think about how to approach this.\\n\\nFirst, I need to recall if there are any specific functions available for accessing Arxiv. The user provided some tools, but looking at the functions, they\\'re both empty. Wait, maybe the functions are placeholders? The description says \"search for paper on the topic mercury from arxiv\" but the parameters are empty. \\n\\nSince the tools are empty, I can\\'t use any functions. But the user is asking for a search. Maybe I should inform them that the current setup doesn\\'t support that functionality. Alternatively, perhaps there\\'s a way to simulate a search using the available tools, even if they\\'re empty. But since the functions are empty, I can\\'t perform any action. \\n\\nI should check if there\\'s any other way. Maybe the assistant can directly provide information, but the tools are not set up for that. Since the user is asking for a search, and the tools aren\\'t functional, the best response is to let them know that the current system can\\'t perform that search. \\n\\nSo, the answer would be to inform the user that the assistant can\\'t perform that task with the current tools. I need to make sure not to use any functions here because they\\'re not available. The user might need to use a different method, like visiting Arxiv directly or using a different tool.\\n</think>\\n\\nI currently don\\'t have access to external search tools or the Arxiv database to perform this search. You might want to try visiting the Arxiv website directly or using a search engine to look for papers on \"mercury\" in the physics or planetary science categories. Let me know if you\\'d like help formulating a search query!')\n",
      "('images', None)\n",
      "('tool_calls', None)\n"
     ]
    }
   ],
   "source": [
    "for content in response.message:\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90eb28f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('model', 'qwen3:1.7b')\n",
      "('created_at', '2025-07-16T17:06:27.7576121Z')\n",
      "('done', True)\n",
      "('done_reason', 'stop')\n",
      "('total_duration', 9947200900)\n",
      "('load_duration', 118638900)\n",
      "('prompt_eval_count', 154)\n",
      "('prompt_eval_duration', 344793200)\n",
      "('eval_count', 278)\n",
      "('eval_duration', 9481054300)\n",
      "('message', Message(role='assistant', content=\"<think>\\nOkay, the user is asking for the latest weather in Bangalore. Let me think about how to approach this.\\n\\nFirst, I need to check if there's a function available to get weather data. Looking at the tools provided, there are two functions listed, but their names and descriptions are empty. That's a problem because without knowing the actual functions, I can't use them. \\n\\nWait, maybe the functions are supposed to be part of the system, but in the given tools, they're not detailed. The user might have intended to include weather-related functions, but they weren't properly formatted. \\n\\nSince I can't use the functions as they are, I need to inform the user that I can't retrieve the latest weather data because the necessary tools aren't available. I should apologize and explain the limitation. \\n\\nAlso, the user might be expecting an answer, but without the right tools, I can't provide that. So, the best response is to let them know the current situation and suggest checking a weather service for real-time updates.\\n</think>\\n\\nI currently don't have access to real-time weather data or the ability to check current weather conditions. You might want to check a weather service like Weather.com, AccuWeather, or a dedicated weather app for the latest updates on Bangalore's weather. Let me know if there's anything else I can help with!\", images=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "for content in response:\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ac9a79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(role='assistant', content=\"<think>\\nOkay, the user is asking for the latest weather in Bangalore. Let me think about how to approach this.\\n\\nFirst, I need to check if there's a function available to get weather data. Looking at the tools provided, there are two functions listed, but their names and descriptions are empty. That's a problem because without knowing the actual functions, I can't use them. \\n\\nWait, maybe the functions are supposed to be part of the system, but in the given tools, they're not detailed. The user might have intended to include weather-related functions, but they weren't properly formatted. \\n\\nSince I can't use the functions as they are, I need to inform the user that I can't retrieve the latest weather data because the necessary tools aren't available. I should apologize and explain the limitation. \\n\\nAlso, the user might be expecting an answer, but without the right tools, I can't provide that. So, the best response is to let them know the current situation and suggest checking a weather service for real-time updates.\\n</think>\\n\\nI currently don't have access to real-time weather data or the ability to check current weather conditions. You might want to check a weather service like Weather.com, AccuWeather, or a dedicated weather app for the latest updates on Bangalore's weather. Let me know if there's anything else I can help with!\", images=None, tool_calls=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "935169f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, the user is asking for the latest weather in Bangalore. Let me think about how to approach this.\\n\\nFirst, I need to check if there's a function available to get weather data. Looking at the tools provided, there are two functions listed, but their names and descriptions are empty. That's a problem because without knowing the actual functions, I can't use them. \\n\\nWait, maybe the functions are supposed to be part of the system, but in the given tools, they're not detailed. The user might have intended to include weather-related functions, but they weren't properly formatted. \\n\\nSince I can't use the functions as they are, I need to inform the user that I can't retrieve the latest weather data because the necessary tools aren't available. I should apologize and explain the limitation. \\n\\nAlso, the user might be expecting an answer, but without the right tools, I can't provide that. So, the best response is to let them know the current situation and suggest checking a weather service for real-time updates.\\n</think>\\n\\nI currently don't have access to real-time weather data or the ability to check current weather conditions. You might want to check a weather service like Weather.com, AccuWeather, or a dedicated weather app for the latest updates on Bangalore's weather. Let me know if there's anything else I can help with!\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175586b4-acdf-4103-8039-134478a4f797",
   "metadata": {},
   "source": [
    "### Query Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a896e0-3f56-417e-aa51-c61756048593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    \n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "    \n",
    "    response = client.chat(model = 'qwen3:1.7b', \n",
    "                                  tools = tools,\n",
    "                                  messages = messages)\n",
    "    \n",
    "    process_query = True\n",
    "    while process_query:\n",
    "        assistant_content = []\n",
    "\n",
    "        for content in response:\n",
    "            if content.type == 'text':\n",
    "                \n",
    "                print(content.text)\n",
    "                assistant_content.append(content)\n",
    "                \n",
    "                if len(response.content) == 1:\n",
    "                    process_query = False\n",
    "            \n",
    "            elif response.message.tool_calls:\n",
    "                \n",
    "                assistant_content.append(response.message.content)\n",
    "                messages.append({'role': 'assistant', 'content': assistant_content})\n",
    "                \n",
    "                tool_id = content.id\n",
    "                tool_args = content.input\n",
    "                tool_name = content.name\n",
    "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                \n",
    "                result = execute_tool(tool_name, tool_args)\n",
    "                messages.append({\"role\": \"user\", \n",
    "                                  \"content\": [\n",
    "                                      {\n",
    "                                          \"type\": \"tool_result\",\n",
    "                                          \"tool_use_id\": tool_id,\n",
    "                                          \"content\": result\n",
    "                                      }\n",
    "                                  ]\n",
    "                                })\n",
    "                response = client.messages.create(max_tokens = 2024,\n",
    "                                  model = 'claude-3-7-sonnet-20250219', \n",
    "                                  tools = tools,\n",
    "                                  messages = messages) \n",
    "                \n",
    "                if len(response.content) == 1 and response.content[0].type == \"text\":\n",
    "                    print(response.content[0].text)\n",
    "                    process_query = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2921ee7f-d2be-464b-ab7b-8db2a3c13ba9",
   "metadata": {},
   "source": [
    "### Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16979cdc-81e9-432b-ba7f-e810b52961e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "    \n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfaf254-f22a-4951-885e-1d21fbc41ff3",
   "metadata": {},
   "source": [
    "Feel free to interact with the chatbot. Here's an example query: \n",
    "\n",
    "- Search for 2 papers on \"LLM interpretability\"\n",
    "\n",
    "To access the `papers` folder: 1) click on the `File` option on the top menu of the notebook and 2) click on `Open` and then 3) click on `L3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39676f70-1c72-4da3-8363-da281bd5a83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:  Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm here to help you search for and extract information about academic papers on arXiv. I can help you:\n",
      "\n",
      "1. Search for papers on a specific topic\n",
      "2. Get detailed information about a specific paper using its ID\n",
      "\n",
      "What would you like to know about? Please let me know if you'd like to search for papers on a particular topic or learn more about a specific paper.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:  search for MCP related application in protein biology\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll search for papers related to MCP applications in protein biology. MCP likely refers to \"Methyl-accepting Chemotaxis Protein\" or possibly \"Multiple Chemical Programming\" in this context, but I'll search broadly to capture relevant papers.\n",
      "Calling tool search_papers with args {'topic': 'MCP protein biology application', 'max_results': 5}\n",
      "Results are saved in: papers/mcp_protein_biology_application/papers_info.json\n",
      "Let me retrieve detailed information about each of these papers to see how they relate to MCP and protein biology:\n",
      "Calling tool extract_info with args {'paper_id': '2504.08999v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2504.12757v2'}\n",
      "Calling tool extract_info with args {'paper_id': '1610.04116v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2105.03617v1'}\n",
      "Calling tool extract_info with args {'paper_id': '1711.03897v2'}\n",
      "Based on the search results, I can provide you with information about MCP applications in protein biology:\n",
      "\n",
      "I notice that the search returned different meanings of \"MCP\" across the papers:\n",
      "\n",
      "1. In the first two papers (2504.08999v1 and 2504.12757v2), MCP refers to \"Model Context Protocol\" - a protocol for AI systems rather than protein biology applications.\n",
      "\n",
      "2. The third paper (1610.04116v1) discusses protein scaling theory but doesn't specifically focus on MCP in the context of proteins.\n",
      "\n",
      "3. The fourth paper (2105.03617v1) is about protein-protein interactions and docking software (MEGADOCK-GUI) but doesn't explicitly mention MCP.\n",
      "\n",
      "4. The fifth paper (1711.03897v2) discusses \"Multi Micro-Channel-Plates\" (MCPs) for photon counting detectors, which is a physics application rather than protein biology.\n",
      "\n",
      "It appears the search didn't return papers specifically about Methyl-accepting Chemotaxis Proteins (MCPs) in biology. Would you like me to perform a more specific search using terms like \"methyl-accepting chemotaxis protein\" or \"MCP bacterial chemotaxis\" to find more relevant papers about MCPs in protein biology?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508916f3-8fa1-4e21-bfa7-081a810bc36c",
   "metadata": {},
   "source": [
    "In the next lessons, you will take out the tool definitions to wrap them in an MCP server. Then you will create an MCP client inside the chatbot to make the chatbot MCP compatible.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02d207b-e07d-49ff-bb03-7954aa86c167",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "[Guide on how to implement tool use](https://docs.anthropic.com/en/docs/build-with-claude/tool-use/overview#how-to-implement-tool-use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b29b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the Anthropic-based process_query with an Ollama-based version\n",
    "\n",
    "def process_query(query, model=\"llama3\"):\n",
    "    \"\"\"\n",
    "    Process a user query using a local Ollama LLM.\n",
    "    Args:\n",
    "        query (str): The user input prompt.\n",
    "        model (str): The Ollama model to use (default: 'llama3').\n",
    "    Returns:\n",
    "        str: The LLM's response.\n",
    "    \"\"\"\n",
    "    import ollama\n",
    "    response = ollama.chat(model=model, messages=[{\"role\": \"user\", \"content\": query}])\n",
    "    return response[\"message\"][\"content\"]\n",
    "\n",
    "# Example usage:\n",
    "# print(process_query(\"What is MCP?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2730a90",
   "metadata": {},
   "source": [
    "## Ollama Function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04fdb8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import yfinance as yf \n",
    "from typing import Dict,Any, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b000ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_price(symbol:str) -> float:\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    price_attrs = ['regularMarketPrice', 'currentPrice', 'price']\n",
    "\n",
    "    for attr in price_attrs:\n",
    "        if attr in ticker.info and ticker.info[attr] is not None:\n",
    "            return ticker.info[attr]\n",
    "        \n",
    "    fast_info = ticker.fast_info\n",
    "    if hasattr(fast_info,'last_price') and fast_info.last_price is not None:\n",
    "        return fast_info.last_price\n",
    "    raise Exception(\"Could not find any info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ddf079c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180.498"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stock_price(\"GOOGL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35714451",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stock_price_tool = {\n",
    "    'type': 'function',\n",
    "    'function': {\n",
    "        'name': 'get_stock_price',\n",
    "        'description': 'Get the current stock price for any symbol',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'required': ['symbol'],\n",
    "            'properties': {\n",
    "                'symbol': {'type': 'string', 'description': 'The stock symbol (e.g., AAPL, GOOGL)'},\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f71fd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is the current stock price of Apple?\n"
     ]
    }
   ],
   "source": [
    "prompt = 'What is the current stock price of Apple?'\n",
    "print('Prompt:', prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "191f90f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_functions:Dict[str,Callable] = {\n",
    "    'get_stock_price' :get_stock_price\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdabb2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.chat(\n",
    "    'qwen3:1.7b',\n",
    "    messages=[{'role':'user', 'content':prompt}],\n",
    "    tools = [get_stock_price]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9ee83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(model='qwen3:1.7b', created_at='2025-07-14T16:43:20.1356194Z', done=True, done_reason='stop', total_duration=11528222200, load_duration=7940143600, prompt_eval_count=140, prompt_eval_duration=1089402100, eval_count=107, eval_duration=2481158100, message=Message(role='assistant', content='<think>\\nOkay, the user is asking for the current stock price of Apple. Let me check the tools available. There\\'s a function called get_stock_price which requires a symbol parameter. Apple\\'s stock symbol is AAPL. So I need to call this function with the symbol \"AAPL\". I should make sure the parameters are correctly formatted as JSON within the tool_call tags. Let me structure the response properly.\\n</think>\\n\\n', images=None, tool_calls=[ToolCall(function=Function(name='get_stock_price', arguments={'symbol': 'AAPL'}))]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f001c173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling function: get_stock_price\n",
      "Arguments: {'symbol': 'AAPL'}\n",
      "Function output: 209.05\n"
     ]
    }
   ],
   "source": [
    "if response.message.tool_calls:\n",
    "    for tool in response.message.tool_calls:\n",
    "        if function_to_call := available_functions.get(tool.function.name):\n",
    "            print('Calling function:', tool.function.name)\n",
    "            print('Arguments:', tool.function.arguments)\n",
    "            print('Function output:', function_to_call(**tool.function.arguments))\n",
    "        else:\n",
    "            print('Function', tool.function.name, 'not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9980c5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 6, 18, 0, 35, 9, 741285, tzinfo=TzInfo(+05:30)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M')),\n",
       " Model(model='qwen3:1.7b', modified_at=datetime.datetime(2025, 6, 13, 0, 0, 55, 230752, tzinfo=TzInfo(+05:30)), digest='8f68893c685c3ddff2aa3fffce2aa60a30bb2da65ca488b61fff134a4d1730e7', size=1359293444, details=ModelDetails(parent_model='', format='gguf', family='qwen3', families=['qwen3'], parameter_size='2.0B', quantization_level='Q4_K_M')),\n",
       " Model(model='gemma3:1b', modified_at=datetime.datetime(2025, 5, 10, 11, 10, 25, 297843, tzinfo=TzInfo(+05:30)), digest='8648f39daa8fbf5b18c7b4e6a8fb4990c692751d49917417b8842ca5758e7ffc', size=815319791, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='999.89M', quantization_level='Q4_K_M'))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "ollama.list().models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df499000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking for the stock price of Ford. Let me check the tools available. There's a function called get_stock_price that takes a symbol parameter. Ford's stock symbol is F. So I need to call this function with symbol \"F\". Let me make sure I have the correct symbol. Yes, Ford is listed as F on the stock market. Alright, I'll use that function to retrieve the current price.\n",
      "</think>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "response: ChatResponse = chat(model='qwen3:1.7b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'what is the stock price of Ford',\n",
    "  }\n",
    "],\n",
    "tools=[get_stock_price_tool])# or access fields directly from the response object\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "023cf797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolCall(function=Function(name='get_stock_price', arguments={'symbol': 'F'}))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90a04299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant\n",
      "<think>\n",
      "Okay, the user is asking for the stock price of Ford. Let me check the tools available. There's a function called get_stock_price that takes a symbol parameter. Ford's stock symbol is F. So I need to call this function with symbol \"F\". Let me make sure I have the correct symbol. Yes, Ford is listed as F on the stock market. Alright, I'll use that function to retrieve the current price.\n",
      "</think>\n",
      "\n",
      "\n",
      "None\n",
      "[ToolCall(function=Function(name='get_stock_price', arguments={'symbol': 'F'}))]\n",
      "('tool_calls', [ToolCall(function=Function(name='get_stock_price', arguments={'symbol': 'F'}))])\n"
     ]
    }
   ],
   "source": [
    "for content in response.message:\n",
    "    print(content[1])\n",
    "    if content[0] == 'tool_calls':\n",
    "        print(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
