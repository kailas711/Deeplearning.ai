{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c10b768-f5b4-43bc-a785-99077422ce78",
   "metadata": {},
   "source": [
    "# Lesson 3: Chatbot Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d4fedc-4b90-4754-9f2d-fd3cfa321a14",
   "metadata": {},
   "source": [
    "In this lesson, you will familiarize yourself with the chatbot example you will work on during this course. The example includes the tool definitions and execution, as well as the chatbot code. Make sure to interact with the chatbot at the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ed96ba-5ade-4af4-9096-406ce48d5cf2",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dd6bd1d4-f652-45d1-9efa-155a2cc01713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20f163a-87af-4e0c-87ed-1624c150c572",
   "metadata": {},
   "source": [
    "## Tool Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "549a7f46-74b3-4a1d-b084-055c99e3c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_DIR = \"papers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e43905e-56f3-404c-a322-f038055e9b1c",
   "metadata": {},
   "source": [
    "The first tool searches for relevant arXiv papers based on a topic and stores the papers' info in a JSON file (title, authors, summary, paper url and the publication date). The JSON files are organized by topics in the `papers` directory. The tool does not download the papers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "886633b8-ce67-4343-822d-cc3f98f953fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use arxiv to find the papers \n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "    \n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info  \n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "    \n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "    \n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "    \n",
    "    return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d20ee17a-afe6-438a-95b1-6e87742c7fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers\\agentic_ai_in_protein_sequences\\papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2502.10173v1',\n",
       " '2504.16479v1',\n",
       " '2312.03016v1',\n",
       " '2402.04268v1',\n",
       " '2504.19017v1']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_papers(\"Agentic AI in protein sequences\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb83565-69af-47f3-9ba3-a96965cff7df",
   "metadata": {},
   "source": [
    "The second tool looks for information about a specific paper across all topic directories inside the `papers` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df9b1997-81cd-447d-9665-1cb72d93bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    " \n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return f\"There's no saved information related to paper {paper_id}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0ebe0de7-8f07-4e08-a670-7b371fc3d2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"title\": \"Compact manifolds with computable boundaries\",\\n  \"authors\": [\\n    \"Zvonko Iljazovic\"\\n  ],\\n  \"summary\": \"We investigate conditions under which a co-computably enumerable closed set\\\\nin a computable metric space is computable and prove that in each locally\\\\ncomputable computable metric space each co-computably enumerable compact\\\\nmanifold with computable boundary is computable. In fact, we examine the notion\\\\nof a semi-computable compact set and we prove a more general result: in any\\\\ncomputable metric space each semi-computable compact manifold with computable\\\\nboundary is computable. In particular, each semi-computable compact\\\\n(boundaryless) manifold is computable.\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/1310.7911v2\",\\n  \"published\": \"2013-10-29\"\\n}'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_info('1310.7911v2')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea3013-e690-4bc8-8622-27b4d42d61e4",
   "metadata": {},
   "source": [
    "## Tool Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d2260-452d-472a-b56e-326479cb18c9",
   "metadata": {},
   "source": [
    "Here are the schema of each tool which you will provide to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0af714c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='llama3.1',\n",
    "    messages=[{'role': 'user', 'content':\n",
    "        'What is the weather in Toronto?'}],\n",
    "\n",
    "\t\t# provide a weather checking tool to the model\n",
    "    tools=[{\n",
    "      'type': 'function',\n",
    "      'function': {\n",
    "        'name': 'get_current_weather',\n",
    "        'description': 'Get the current weather for a city',\n",
    "        'parameters': {\n",
    "          'type': 'object',\n",
    "          'properties': {\n",
    "            'city': {\n",
    "              'type': 'string',\n",
    "              'description': 'The name of the city',\n",
    "            },\n",
    "          },\n",
    "          'required': ['city'],\n",
    "        },\n",
    "      },\n",
    "    },\n",
    "  ],\n",
    ")\n",
    "\n",
    "print(response['message']['tool_calls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dadf73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools=[{\n",
    "    'type': 'function',\n",
    "    'function': {\n",
    "    'name': 'get_current_weather',\n",
    "    'description': 'Get the current weather for a city',\n",
    "    'parameters': {\n",
    "        'type': 'object',\n",
    "        'properties': {\n",
    "        'city': {\n",
    "            'type': 'string',\n",
    "            'description': 'The name of the city',\n",
    "        },\n",
    "        },\n",
    "        'required': ['city'],\n",
    "    },\n",
    "    },\n",
    "},\n",
    "\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e5bdea5f-e93a-4018-8c13-00d5ee10c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"name\": \"search_papers\",\n",
    "        \"description\": \"Search for papers on arXiv based on a topic and store their information.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"topic\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The topic to search for\"\n",
    "                }, \n",
    "                \"max_results\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Maximum number of results to retrieve\",\n",
    "                    \"default\": 5\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"topic\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"extract_info\",\n",
    "        \"description\": \"Search for information about a specific paper across all topic directories.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"paper_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The ID of the paper to look for\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"paper_id\"]\n",
    "        }\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec668d24-1559-41b7-bc8a-e2dca77dfaf2",
   "metadata": {},
   "source": [
    "## Tool Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c728c1ec-36b1-48b4-9f85-622464ac79f4",
   "metadata": {},
   "source": [
    "This code handles tool mapping and execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c90790c0-efc4-4068-9c00-d2592d80bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info\n",
    "}\n",
    "\n",
    "def execute_tool(tool_name, tool_args):\n",
    "    \n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "\n",
    "    if result is None:\n",
    "        result = \"The operation completed but didn't return any results.\"\n",
    "        \n",
    "    elif isinstance(result, list):\n",
    "        result = ', '.join(result)\n",
    "        \n",
    "    elif isinstance(result, dict):\n",
    "        # Convert dictionaries to formatted JSON strings\n",
    "        result = json.dumps(result, indent=2)\n",
    "    \n",
    "    else:\n",
    "        # For any other type, convert using str()\n",
    "        result = str(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8fc4d3-58ac-482c-8bbd-bccd6ef9fc31",
   "metadata": {},
   "source": [
    "## Chatbot Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba0fad-b0e4-4415-a431-341e9ca85087",
   "metadata": {},
   "source": [
    "The chatbot handles the user's queries one by one, but it does not persist memory across the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fe662400-8506-464e-a3da-75a3d8848bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama \n",
    "from ollama import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='qwen3:1.7b',\n",
    "    messages=[{'role': 'user', 'content':\n",
    "        'What is the latest weather in bangalore? '}],\n",
    "\n",
    "\t\t# provide a weather checking tool to the model\n",
    "    tools=tools\n",
    ")\n",
    "        \n",
    "# load_dotenv() \n",
    "# client = anthropic.Anthropic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2b3ec314",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(role='assistant', content='<think>\\nOkay, the user is asking for the latest weather in Bangalore. Let me check the tools available. There\\'s a function called get_current_weather that requires the city name. Since Bangalore is a city, I can use this function. I need to make sure to pass the city parameter as \"Bangalore\" in the arguments. No other parameters are needed. So the tool call should be straightforward. Just call get_current_weather with the city set to Bangalore.\\n</think>\\n\\n', images=None, tool_calls=[ToolCall(function=Function(name='get_current_weather', arguments={'city': 'Bangalore'}))])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175586b4-acdf-4103-8039-134478a4f797",
   "metadata": {},
   "source": [
    "### Query Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "12a896e0-3f56-417e-aa51-c61756048593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    \n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "    \n",
    "    response = client.messages.create(max_tokens = 2024,\n",
    "                                  model = 'claude-3-7-sonnet-20250219', \n",
    "                                  tools = tools,\n",
    "                                  messages = messages)\n",
    "    \n",
    "    process_query = True\n",
    "    while process_query:\n",
    "        assistant_content = []\n",
    "\n",
    "        for content in response.content:\n",
    "            if content.type == 'text':\n",
    "                \n",
    "                print(content.text)\n",
    "                assistant_content.append(content)\n",
    "                \n",
    "                if len(response.content) == 1:\n",
    "                    process_query = False\n",
    "            \n",
    "            elif content.type == 'tool_use':\n",
    "                \n",
    "                assistant_content.append(content)\n",
    "                messages.append({'role': 'assistant', 'content': assistant_content})\n",
    "                \n",
    "                tool_id = content.id\n",
    "                tool_args = content.input\n",
    "                tool_name = content.name\n",
    "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                \n",
    "                result = execute_tool(tool_name, tool_args)\n",
    "                messages.append({\"role\": \"user\", \n",
    "                                  \"content\": [\n",
    "                                      {\n",
    "                                          \"type\": \"tool_result\",\n",
    "                                          \"tool_use_id\": tool_id,\n",
    "                                          \"content\": result\n",
    "                                      }\n",
    "                                  ]\n",
    "                                })\n",
    "                response = client.messages.create(max_tokens = 2024,\n",
    "                                  model = 'claude-3-7-sonnet-20250219', \n",
    "                                  tools = tools,\n",
    "                                  messages = messages) \n",
    "                \n",
    "                if len(response.content) == 1 and response.content[0].type == \"text\":\n",
    "                    print(response.content[0].text)\n",
    "                    process_query = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2921ee7f-d2be-464b-ab7b-8db2a3c13ba9",
   "metadata": {},
   "source": [
    "### Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16979cdc-81e9-432b-ba7f-e810b52961e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "    \n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfaf254-f22a-4951-885e-1d21fbc41ff3",
   "metadata": {},
   "source": [
    "Feel free to interact with the chatbot. Here's an example query: \n",
    "\n",
    "- Search for 2 papers on \"LLM interpretability\"\n",
    "\n",
    "To access the `papers` folder: 1) click on the `File` option on the top menu of the notebook and 2) click on `Open` and then 3) click on `L3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39676f70-1c72-4da3-8363-da281bd5a83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:  Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm here to help you search for and extract information about academic papers on arXiv. I can help you:\n",
      "\n",
      "1. Search for papers on a specific topic\n",
      "2. Get detailed information about a specific paper using its ID\n",
      "\n",
      "What would you like to know about? Please let me know if you'd like to search for papers on a particular topic or learn more about a specific paper.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:  search for MCP related application in protein biology\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll search for papers related to MCP applications in protein biology. MCP likely refers to \"Methyl-accepting Chemotaxis Protein\" or possibly \"Multiple Chemical Programming\" in this context, but I'll search broadly to capture relevant papers.\n",
      "Calling tool search_papers with args {'topic': 'MCP protein biology application', 'max_results': 5}\n",
      "Results are saved in: papers/mcp_protein_biology_application/papers_info.json\n",
      "Let me retrieve detailed information about each of these papers to see how they relate to MCP and protein biology:\n",
      "Calling tool extract_info with args {'paper_id': '2504.08999v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2504.12757v2'}\n",
      "Calling tool extract_info with args {'paper_id': '1610.04116v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2105.03617v1'}\n",
      "Calling tool extract_info with args {'paper_id': '1711.03897v2'}\n",
      "Based on the search results, I can provide you with information about MCP applications in protein biology:\n",
      "\n",
      "I notice that the search returned different meanings of \"MCP\" across the papers:\n",
      "\n",
      "1. In the first two papers (2504.08999v1 and 2504.12757v2), MCP refers to \"Model Context Protocol\" - a protocol for AI systems rather than protein biology applications.\n",
      "\n",
      "2. The third paper (1610.04116v1) discusses protein scaling theory but doesn't specifically focus on MCP in the context of proteins.\n",
      "\n",
      "3. The fourth paper (2105.03617v1) is about protein-protein interactions and docking software (MEGADOCK-GUI) but doesn't explicitly mention MCP.\n",
      "\n",
      "4. The fifth paper (1711.03897v2) discusses \"Multi Micro-Channel-Plates\" (MCPs) for photon counting detectors, which is a physics application rather than protein biology.\n",
      "\n",
      "It appears the search didn't return papers specifically about Methyl-accepting Chemotaxis Proteins (MCPs) in biology. Would you like me to perform a more specific search using terms like \"methyl-accepting chemotaxis protein\" or \"MCP bacterial chemotaxis\" to find more relevant papers about MCPs in protein biology?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508916f3-8fa1-4e21-bfa7-081a810bc36c",
   "metadata": {},
   "source": [
    "In the next lessons, you will take out the tool definitions to wrap them in an MCP server. Then you will create an MCP client inside the chatbot to make the chatbot MCP compatible.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02d207b-e07d-49ff-bb03-7954aa86c167",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "[Guide on how to implement tool use](https://docs.anthropic.com/en/docs/build-with-claude/tool-use/overview#how-to-implement-tool-use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b29b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the Anthropic-based process_query with an Ollama-based version\n",
    "\n",
    "def process_query(query, model=\"llama3\"):\n",
    "    \"\"\"\n",
    "    Process a user query using a local Ollama LLM.\n",
    "    Args:\n",
    "        query (str): The user input prompt.\n",
    "        model (str): The Ollama model to use (default: 'llama3').\n",
    "    Returns:\n",
    "        str: The LLM's response.\n",
    "    \"\"\"\n",
    "    import ollama\n",
    "    response = ollama.chat(model=model, messages=[{\"role\": \"user\", \"content\": query}])\n",
    "    return response[\"message\"][\"content\"]\n",
    "\n",
    "# Example usage:\n",
    "# print(process_query(\"What is MCP?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2730a90",
   "metadata": {},
   "source": [
    "## Ollama Function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04fdb8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import yfinance as yf \n",
    "from typing import Dict,Any, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b000ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_price(symbol:str) -> float:\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    price_attrs = ['regularMarketPrice', 'currentPrice', 'price']\n",
    "\n",
    "    for attr in price_attrs:\n",
    "        if attr in ticker.info and ticker.info[attr] is not None:\n",
    "            return ticker.info[attr]\n",
    "        \n",
    "    fast_info = ticker.fast_info\n",
    "    if hasattr(fast_info,'last_price') and fast_info.last_price is not None:\n",
    "        return fast_info.last_price\n",
    "    raise Exception(\"Could not find any info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ddf079c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180.498"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stock_price(\"GOOGL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35714451",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stock_price_tool = {\n",
    "    'type': 'function',\n",
    "    'function': {\n",
    "        'name': 'get_stock_price',\n",
    "        'description': 'Get the current stock price for any symbol',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'required': ['symbol'],\n",
    "            'properties': {\n",
    "                'symbol': {'type': 'string', 'description': 'The stock symbol (e.g., AAPL, GOOGL)'},\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f71fd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is the current stock price of Apple?\n"
     ]
    }
   ],
   "source": [
    "prompt = 'What is the current stock price of Apple?'\n",
    "print('Prompt:', prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "191f90f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_functions:Dict[str,Callable] = {\n",
    "    'get_stock_price' :get_stock_price\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdabb2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.chat(\n",
    "    'qwen3:1.7b',\n",
    "    messages=[{'role':'user', 'content':prompt}],\n",
    "    tools = [get_stock_price]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9ee83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(model='qwen3:1.7b', created_at='2025-07-14T16:43:20.1356194Z', done=True, done_reason='stop', total_duration=11528222200, load_duration=7940143600, prompt_eval_count=140, prompt_eval_duration=1089402100, eval_count=107, eval_duration=2481158100, message=Message(role='assistant', content='<think>\\nOkay, the user is asking for the current stock price of Apple. Let me check the tools available. There\\'s a function called get_stock_price which requires a symbol parameter. Apple\\'s stock symbol is AAPL. So I need to call this function with the symbol \"AAPL\". I should make sure the parameters are correctly formatted as JSON within the tool_call tags. Let me structure the response properly.\\n</think>\\n\\n', images=None, tool_calls=[ToolCall(function=Function(name='get_stock_price', arguments={'symbol': 'AAPL'}))]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f001c173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling function: get_stock_price\n",
      "Arguments: {'symbol': 'AAPL'}\n",
      "Function output: 209.05\n"
     ]
    }
   ],
   "source": [
    "if response.message.tool_calls:\n",
    "    for tool in response.message.tool_calls:\n",
    "        if function_to_call := available_functions.get(tool.function.name):\n",
    "            print('Calling function:', tool.function.name)\n",
    "            print('Arguments:', tool.function.arguments)\n",
    "            print('Function output:', function_to_call(**tool.function.arguments))\n",
    "        else:\n",
    "            print('Function', tool.function.name, 'not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9980c5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 6, 18, 0, 35, 9, 741285, tzinfo=TzInfo(+05:30)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M')),\n",
       " Model(model='qwen3:1.7b', modified_at=datetime.datetime(2025, 6, 13, 0, 0, 55, 230752, tzinfo=TzInfo(+05:30)), digest='8f68893c685c3ddff2aa3fffce2aa60a30bb2da65ca488b61fff134a4d1730e7', size=1359293444, details=ModelDetails(parent_model='', format='gguf', family='qwen3', families=['qwen3'], parameter_size='2.0B', quantization_level='Q4_K_M')),\n",
       " Model(model='gemma3:1b', modified_at=datetime.datetime(2025, 5, 10, 11, 10, 25, 297843, tzinfo=TzInfo(+05:30)), digest='8648f39daa8fbf5b18c7b4e6a8fb4990c692751d49917417b8842ca5758e7ffc', size=815319791, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='999.89M', quantization_level='Q4_K_M'))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "ollama.list().models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df499000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking for the stock price of Ford. Let me check the tools available. There's a function called get_stock_price that takes a symbol parameter. Ford's stock symbol is F. So I need to call this function with symbol \"F\". Let me make sure I have the correct symbol. Yes, Ford is listed as F on the stock market. Alright, I'll use that function to retrieve the current price.\n",
      "</think>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "response: ChatResponse = chat(model='qwen3:1.7b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'what is the stock price of Ford',\n",
    "  }\n",
    "],\n",
    "tools=[get_stock_price_tool])# or access fields directly from the response object\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "023cf797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolCall(function=Function(name='get_stock_price', arguments={'symbol': 'F'}))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90a04299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant\n",
      "<think>\n",
      "Okay, the user is asking for the stock price of Ford. Let me check the tools available. There's a function called get_stock_price that takes a symbol parameter. Ford's stock symbol is F. So I need to call this function with symbol \"F\". Let me make sure I have the correct symbol. Yes, Ford is listed as F on the stock market. Alright, I'll use that function to retrieve the current price.\n",
      "</think>\n",
      "\n",
      "\n",
      "None\n",
      "[ToolCall(function=Function(name='get_stock_price', arguments={'symbol': 'F'}))]\n",
      "('tool_calls', [ToolCall(function=Function(name='get_stock_price', arguments={'symbol': 'F'}))])\n"
     ]
    }
   ],
   "source": [
    "for content in response.message:\n",
    "    print(content[1])\n",
    "    if content[0] == 'tool_calls':\n",
    "        print(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
