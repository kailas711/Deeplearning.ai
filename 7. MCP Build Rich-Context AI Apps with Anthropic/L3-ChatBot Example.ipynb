{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c10b768-f5b4-43bc-a785-99077422ce78",
   "metadata": {},
   "source": [
    "# Lesson 3: Chatbot Example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d4fedc-4b90-4754-9f2d-fd3cfa321a14",
   "metadata": {},
   "source": [
    "In this lesson, you will familiarize yourself with the chatbot example you will work on during this course. The example includes the tool definitions and execution, as well as the chatbot code. Make sure to interact with the chatbot at the end of this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e0ed96ba-5ade-4af4-9096-406ce48d5cf2",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd6bd1d4-f652-45d1-9efa-155a2cc01713",
   "metadata": {},
   "outputs": [],
   "source": [
    "import arxiv\n",
    "import json\n",
    "import os\n",
    "from typing import List\n",
    "from dotenv import load_dotenv\n",
    "import anthropic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f20f163a-87af-4e0c-87ed-1624c150c572",
   "metadata": {},
   "source": [
    "## Tool Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "549a7f46-74b3-4a1d-b084-055c99e3c318",
   "metadata": {},
   "outputs": [],
   "source": [
    "PAPER_DIR = \"papers\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e43905e-56f3-404c-a322-f038055e9b1c",
   "metadata": {},
   "source": [
    "The first tool searches for relevant arXiv papers based on a topic and stores the papers' info in a JSON file (title, authors, summary, paper url and the publication date). The JSON files are organized by topics in the `papers` directory. The tool does not download the papers.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "886633b8-ce67-4343-822d-cc3f98f953fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import List\n",
    "\n",
    "def search_papers(topic: str, max_results: int = 5) -> List[str]:\n",
    "    \"\"\"\n",
    "    Search for papers on arXiv based on a topic and store their information.\n",
    "    \n",
    "    Args:\n",
    "        topic: The topic to search for\n",
    "        max_results: Maximum number of results to retrieve (default: 5)\n",
    "        \n",
    "    Returns:\n",
    "        List of paper IDs found in the search\n",
    "    \"\"\"\n",
    "    \n",
    "    # Use arxiv to find the papers \n",
    "    client = arxiv.Client()\n",
    "\n",
    "    # Search for the most relevant articles matching the queried topic\n",
    "    search = arxiv.Search(\n",
    "        query = topic,\n",
    "        max_results = max_results,\n",
    "        sort_by = arxiv.SortCriterion.Relevance\n",
    "    )\n",
    "\n",
    "    papers = client.results(search)\n",
    "    \n",
    "    # Create directory for this topic\n",
    "    path = os.path.join(PAPER_DIR, topic.lower().replace(\" \", \"_\"))\n",
    "    os.makedirs(path, exist_ok=True)\n",
    "    \n",
    "    file_path = os.path.join(path, \"papers_info.json\")\n",
    "\n",
    "    # Try to load existing papers info\n",
    "    try:\n",
    "        with open(file_path, \"r\") as json_file:\n",
    "            papers_info = json.load(json_file)\n",
    "    except (FileNotFoundError, json.JSONDecodeError):\n",
    "        papers_info = {}\n",
    "\n",
    "    # Process each paper and add to papers_info  \n",
    "    paper_ids = []\n",
    "    for paper in papers:\n",
    "        paper_ids.append(paper.get_short_id())\n",
    "        paper_info = {\n",
    "            'title': paper.title,\n",
    "            'authors': [author.name for author in paper.authors],\n",
    "            'summary': paper.summary,\n",
    "            'pdf_url': paper.pdf_url,\n",
    "            'published': str(paper.published.date())\n",
    "        }\n",
    "        papers_info[paper.get_short_id()] = paper_info\n",
    "    \n",
    "    # Save updated papers_info to json file\n",
    "    with open(file_path, \"w\") as json_file:\n",
    "        json.dump(papers_info, json_file, indent=2)\n",
    "    \n",
    "    print(f\"Results are saved in: {file_path}\")\n",
    "    \n",
    "    return paper_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d20ee17a-afe6-438a-95b1-6e87742c7fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Results are saved in: papers\\rag_pipelines\\papers_info.json\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['2506.09542v1',\n",
       " '2501.15228v1',\n",
       " '2504.13587v1',\n",
       " '2409.19019v1',\n",
       " '2506.08364v2']"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "search_papers(\"RAG pipelines\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfb83565-69af-47f3-9ba3-a96965cff7df",
   "metadata": {},
   "source": [
    "The second tool looks for information about a specific paper across all topic directories inside the `papers` directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "df9b1997-81cd-447d-9665-1cb72d93bb9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_info(paper_id: str) -> str:\n",
    "    \"\"\"\n",
    "    Search for information about a specific paper across all topic directories.\n",
    "    \n",
    "    Args:\n",
    "        paper_id: The ID of the paper to look for\n",
    "        \n",
    "    Returns:\n",
    "        JSON string with paper information if found, error message if not found\n",
    "    \"\"\"\n",
    " \n",
    "    for item in os.listdir(PAPER_DIR):\n",
    "        item_path = os.path.join(PAPER_DIR, item)\n",
    "        if os.path.isdir(item_path):\n",
    "            file_path = os.path.join(item_path, \"papers_info.json\")\n",
    "            if os.path.isfile(file_path):\n",
    "                try:\n",
    "                    with open(file_path, \"r\") as json_file:\n",
    "                        papers_info = json.load(json_file)\n",
    "                        if paper_id in papers_info:\n",
    "                            return json.dumps(papers_info[paper_id], indent=2)\n",
    "                except (FileNotFoundError, json.JSONDecodeError) as e:\n",
    "                    print(f\"Error reading {file_path}: {str(e)}\")\n",
    "                    continue\n",
    "    \n",
    "    return f\"There's no saved information related to paper {paper_id}.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0ebe0de7-8f07-4e08-a670-7b371fc3d2d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{\\n  \"title\": \"KG-Infused RAG: Augmenting Corpus-Based RAG with External Knowledge Graphs\",\\n  \"authors\": [\\n    \"Dingjun Wu\",\\n    \"Yukun Yan\",\\n    \"Zhenghao Liu\",\\n    \"Zhiyuan Liu\",\\n    \"Maosong Sun\"\\n  ],\\n  \"summary\": \"Retrieval-Augmented Generation (RAG) improves factual accuracy by grounding\\\\nresponses in external knowledge. However, existing methods typically rely on a\\\\nsingle source, either unstructured text or structured knowledge. Moreover, they\\\\nlack cognitively inspired mechanisms for activating relevant knowledge. To\\\\naddress these issues, we propose KG-Infused RAG, a framework that integrates\\\\nKGs into RAG systems to implement spreading activation, a cognitive process\\\\nthat enables concept association and inference. KG-Infused RAG retrieves KG\\\\nfacts, expands the query accordingly, and enhances generation by combining\\\\ncorpus passages with structured facts, enabling interpretable, multi-source\\\\nretrieval grounded in semantic structure. We further improve KG-Infused RAG via\\\\npreference learning on sampled key stages in the pipeline. Experiments on five\\\\nQA benchmarks show that KG-Infused RAG consistently outperforms vanilla RAG (by\\\\n3.8% to 13.8%). Additionally, when integrated into Self-RAG, KG-Infused RAG\\\\nbrings further performance gains, demonstrating its effectiveness and\\\\nversatility as a plug-and-play enhancement module for corpus-based RAG methods.\",\\n  \"pdf_url\": \"http://arxiv.org/pdf/2506.09542v1\",\\n  \"published\": \"2025-06-11\"\\n}'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extract_info('2506.09542v1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ea3013-e690-4bc8-8622-27b4d42d61e4",
   "metadata": {},
   "source": [
    "## Tool Schema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c7d2260-452d-472a-b56e-326479cb18c9",
   "metadata": {},
   "source": [
    "Here are the schema of each tool which you will provide to the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d64ad21d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 6, 18, 0, 35, 9, 741285, tzinfo=TzInfo(+05:30)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M')),\n",
       " Model(model='qwen3:1.7b', modified_at=datetime.datetime(2025, 6, 13, 0, 0, 55, 230752, tzinfo=TzInfo(+05:30)), digest='8f68893c685c3ddff2aa3fffce2aa60a30bb2da65ca488b61fff134a4d1730e7', size=1359293444, details=ModelDetails(parent_model='', format='gguf', family='qwen3', families=['qwen3'], parameter_size='2.0B', quantization_level='Q4_K_M')),\n",
       " Model(model='gemma3:1b', modified_at=datetime.datetime(2025, 5, 10, 11, 10, 25, 297843, tzinfo=TzInfo(+05:30)), digest='8648f39daa8fbf5b18c7b4e6a8fb4990c692751d49917417b8842ca5758e7ffc', size=815319791, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='999.89M', quantization_level='Q4_K_M'))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "ollama.list().models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0af714c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ToolCall(function=Function(name='get_current_weather', arguments={'city': 'Toronto'}))]\n"
     ]
    }
   ],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='qwen3:1.7b',\n",
    "    messages=[{'role': 'user', 'content':\n",
    "        'What is the weather in Toronto?'}],\n",
    "\n",
    "\t\t# provide a weather checking tool to the model\n",
    "    tools=[{\n",
    "      'type': 'function',\n",
    "      'function': {\n",
    "        'name': 'get_current_weather',\n",
    "        'description': 'Get the current weather for a city',\n",
    "        'parameters': {\n",
    "          'type': 'object',\n",
    "          'properties': {\n",
    "            'city': {\n",
    "              'type': 'string',\n",
    "              'description': 'The name of the city',\n",
    "            },\n",
    "          },\n",
    "          'required': ['city'],\n",
    "        },\n",
    "      },\n",
    "    },\n",
    "  ],\n",
    ")\n",
    "\n",
    "print(response['message']['tool_calls'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e5bdea5f-e93a-4018-8c13-00d5ee10c0b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [\n",
    "    {\n",
    "        \"name\": \"search_papers\",\n",
    "        \"description\": \"This tool search for papers on arXiv based on a topic and store their information.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"topic\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The topic to search for\"\n",
    "                }, \n",
    "                \"max_results\": {\n",
    "                    \"type\": \"integer\",\n",
    "                    \"description\": \"Maximum number of results to retrieve\",\n",
    "                    \"default\": 5\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"topic\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"extract_info\",\n",
    "        \"description\": \"This tool search for information about a specific paper across all topic directories.\",\n",
    "        \"input_schema\": {\n",
    "            \"type\": \"object\",\n",
    "            \"properties\": {\n",
    "                \"paper_id\": {\n",
    "                    \"type\": \"string\",\n",
    "                    \"description\": \"The ID of the paper to look for\"\n",
    "                }\n",
    "            },\n",
    "            \"required\": [\"paper_id\"]\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "      'type': 'function',\n",
    "      'function': {\n",
    "        'name': 'get_current_weather',\n",
    "        'description': 'Get the current weather for a city',\n",
    "        'parameters': {\n",
    "          'type': 'object',\n",
    "          'properties': {\n",
    "            'city': {\n",
    "              'type': 'string',\n",
    "              'description': 'The name of the city',\n",
    "            },\n",
    "          },\n",
    "          'required': ['city'],\n",
    "        },\n",
    "      },\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec668d24-1559-41b7-bc8a-e2dca77dfaf2",
   "metadata": {},
   "source": [
    "## Tool Mapping"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c728c1ec-36b1-48b4-9f85-622464ac79f4",
   "metadata": {},
   "source": [
    "This code handles tool mapping and execution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c90790c0-efc4-4068-9c00-d2592d80bc30",
   "metadata": {},
   "outputs": [],
   "source": [
    "mapping_tool_function = {\n",
    "    \"search_papers\": search_papers,\n",
    "    \"extract_info\": extract_info\n",
    "}\n",
    "\n",
    "def execute_tool(tool_name, tool_args):\n",
    "    \n",
    "    result = mapping_tool_function[tool_name](**tool_args)\n",
    "\n",
    "    if result is None:\n",
    "        result = \"The operation completed but didn't return any results.\"\n",
    "        \n",
    "    elif isinstance(result, list):\n",
    "        result = ', '.join(result)\n",
    "        \n",
    "    elif isinstance(result, dict):\n",
    "        # Convert dictionaries to formatted JSON strings\n",
    "        result = json.dumps(result, indent=2)\n",
    "    \n",
    "    else:\n",
    "        # For any other type, convert using str()\n",
    "        result = str(result)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3f38ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'search_papers',\n",
       "  'description': 'This tool search for papers on arXiv based on a topic and store their information.',\n",
       "  'input_schema': {'type': 'object',\n",
       "   'properties': {'topic': {'type': 'string',\n",
       "     'description': 'The topic to search for'},\n",
       "    'max_results': {'type': 'integer',\n",
       "     'description': 'Maximum number of results to retrieve',\n",
       "     'default': 5}},\n",
       "   'required': ['topic']}},\n",
       " {'name': 'extract_info',\n",
       "  'description': 'This tool search for information about a specific paper across all topic directories.',\n",
       "  'input_schema': {'type': 'object',\n",
       "   'properties': {'paper_id': {'type': 'string',\n",
       "     'description': 'The ID of the paper to look for'}},\n",
       "   'required': ['paper_id']}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'get_current_weather',\n",
       "   'description': 'Get the current weather for a city',\n",
       "   'parameters': {'type': 'object',\n",
       "    'properties': {'city': {'type': 'string',\n",
       "      'description': 'The name of the city'}},\n",
       "    'required': ['city']}}}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d8fc4d3-58ac-482c-8bbd-bccd6ef9fc31",
   "metadata": {},
   "source": [
    "## Chatbot Code"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9ba0fad-b0e4-4415-a431-341e9ca85087",
   "metadata": {},
   "source": [
    "The chatbot handles the user's queries one by one, but it does not persist memory across the queries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fe662400-8506-464e-a3da-75a3d8848bac",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tools' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 11\u001b[39m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mollama\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Client\n\u001b[32m      4\u001b[39m client = Client()\n\u001b[32m      6\u001b[39m response = ollama.chat(\n\u001b[32m      7\u001b[39m     model=\u001b[33m'\u001b[39m\u001b[33mqwen3:1.7b\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m      8\u001b[39m     messages=[{\u001b[33m'\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m'\u001b[39m: \u001b[33m'\u001b[39m\u001b[33muser\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m'\u001b[39m:\n\u001b[32m      9\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mwhat is the weather in bangalore\u001b[39m\u001b[33m'\u001b[39m}],\n\u001b[32m     10\u001b[39m \t\t\u001b[38;5;66;03m# provide a weather checking tool to the model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m11\u001b[39m     tools=\u001b[43mtools\u001b[49m\n\u001b[32m     12\u001b[39m )\n",
      "\u001b[31mNameError\u001b[39m: name 'tools' is not defined"
     ]
    }
   ],
   "source": [
    "import ollama \n",
    "from ollama import Client\n",
    "\n",
    "client = Client()\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='qwen3:1.7b',\n",
    "    messages=[{'role': 'user', 'content':\n",
    "        'what is the weather in bangalore'}],\n",
    "\t\t# provide a weather checking tool to the model\n",
    "    tools=tools\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b3ec314",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user wants to search for a paper on mercury from Arxiv. Let me think about how to approach this.\n",
      "\n",
      "First, I need to recall the available tools. The user provided two empty functions, but maybe there's a way to use an external service. Since the functions are empty, perhaps I should use a web search or a specific API.\n",
      "\n",
      "Wait, the user mentioned Arxiv, so maybe the assistant can use a web search function. But the tools given are empty. Hmm. The assistant might not have the capability to perform web searches directly. Alternatively, maybe the assistant is supposed to use a predefined function for searching Arxiv.\n",
      "\n",
      "Wait, the tools section shows two functions with empty names and descriptions. That's confusing. Maybe the assistant is supposed to generate a search query based on the user's input. Since the user is asking for papers on mercury from Arxiv, the assistant could generate a search term like \"mercury\" and use a web search function.\n",
      "\n",
      "But the assistant's tools are empty, so perhaps it's not possible. However, the user might expect the assistant to use a known method. Alternatively, maybe the assistant should inform the user that it can't perform the search with the current tools. But the instructions say to call functions if possible.\n",
      "\n",
      "Wait, the assistant's tools are empty, so there's no function to call. But the user is asking for a search. Since the tools aren't set up, maybe the assistant can't perform the task. However, the assistant should respond by indicating that it can't help with that using the available tools. But the user might expect a different approach.\n",
      "\n",
      "Alternatively, maybe the assistant is supposed to generate a search query and return it. For example, the assistant could say \"Searching for papers on mercury from Arxiv...\" but without using any functions. However, the instructions say to call functions if possible. Since there are no functions, the assistant can't call any. So the correct response would be to inform the user that the assistant can't perform that task with the available tools.\n",
      "\n",
      "But the user might expect a different answer. Maybe the assistant should proceed to use a web search function even if the tools are empty. But since the tools are empty, the assistant can't. Therefore, the assistant should respond that it can't help with that request.\n",
      "</think>\n",
      "\n",
      "I cannot directly search Arxiv for papers, as my current capabilities are limited to the tools provided. However, I can guide you on how to find such papers:  \n",
      "1. Visit the [Arxiv website](https://arxiv.org/) and use the search bar.  \n",
      "2. Type \"mercury\" in the search box and press Enter.  \n",
      "3. Filter results by \"Paper\" type to find relevant academic articles.  \n",
      "\n",
      "Let me know if you need help with anything else!\n"
     ]
    }
   ],
   "source": [
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "4cebc334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('role', 'assistant')\n",
      "('content', '<think>\\nOkay, the user wants to search for a paper on mercury from Arxiv. Let me think about how to approach this.\\n\\nFirst, I need to recall if there are any specific functions available for accessing Arxiv. The user provided some tools, but looking at the functions, they\\'re both empty. Wait, maybe the functions are placeholders? The description says \"search for paper on the topic mercury from arxiv\" but the parameters are empty. \\n\\nSince the tools are empty, I can\\'t use any functions. But the user is asking for a search. Maybe I should inform them that the current setup doesn\\'t support that functionality. Alternatively, perhaps there\\'s a way to simulate a search using the available tools, even if they\\'re empty. But since the functions are empty, I can\\'t perform any action. \\n\\nI should check if there\\'s any other way. Maybe the assistant can directly provide information, but the tools are not set up for that. Since the user is asking for a search, and the tools aren\\'t functional, the best response is to let them know that the current system can\\'t perform that search. \\n\\nSo, the answer would be to inform the user that the assistant can\\'t perform that task with the current tools. I need to make sure not to use any functions here because they\\'re not available. The user might need to use a different method, like visiting Arxiv directly or using a different tool.\\n</think>\\n\\nI currently don\\'t have access to external search tools or the Arxiv database to perform this search. You might want to try visiting the Arxiv website directly or using a search engine to look for papers on \"mercury\" in the physics or planetary science categories. Let me know if you\\'d like help formulating a search query!')\n",
      "('images', None)\n",
      "('tool_calls', None)\n"
     ]
    }
   ],
   "source": [
    "for content in response.message:\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "90eb28f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('model', 'qwen3:1.7b')\n",
      "('created_at', '2025-07-16T17:06:27.7576121Z')\n",
      "('done', True)\n",
      "('done_reason', 'stop')\n",
      "('total_duration', 9947200900)\n",
      "('load_duration', 118638900)\n",
      "('prompt_eval_count', 154)\n",
      "('prompt_eval_duration', 344793200)\n",
      "('eval_count', 278)\n",
      "('eval_duration', 9481054300)\n",
      "('message', Message(role='assistant', content=\"<think>\\nOkay, the user is asking for the latest weather in Bangalore. Let me think about how to approach this.\\n\\nFirst, I need to check if there's a function available to get weather data. Looking at the tools provided, there are two functions listed, but their names and descriptions are empty. That's a problem because without knowing the actual functions, I can't use them. \\n\\nWait, maybe the functions are supposed to be part of the system, but in the given tools, they're not detailed. The user might have intended to include weather-related functions, but they weren't properly formatted. \\n\\nSince I can't use the functions as they are, I need to inform the user that I can't retrieve the latest weather data because the necessary tools aren't available. I should apologize and explain the limitation. \\n\\nAlso, the user might be expecting an answer, but without the right tools, I can't provide that. So, the best response is to let them know the current situation and suggest checking a weather service for real-time updates.\\n</think>\\n\\nI currently don't have access to real-time weather data or the ability to check current weather conditions. You might want to check a weather service like Weather.com, AccuWeather, or a dedicated weather app for the latest updates on Bangalore's weather. Let me know if there's anything else I can help with!\", images=None, tool_calls=None))\n"
     ]
    }
   ],
   "source": [
    "for content in response:\n",
    "    print(content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5ac9a79a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Message(role='assistant', content=\"<think>\\nOkay, the user is asking for the latest weather in Bangalore. Let me think about how to approach this.\\n\\nFirst, I need to check if there's a function available to get weather data. Looking at the tools provided, there are two functions listed, but their names and descriptions are empty. That's a problem because without knowing the actual functions, I can't use them. \\n\\nWait, maybe the functions are supposed to be part of the system, but in the given tools, they're not detailed. The user might have intended to include weather-related functions, but they weren't properly formatted. \\n\\nSince I can't use the functions as they are, I need to inform the user that I can't retrieve the latest weather data because the necessary tools aren't available. I should apologize and explain the limitation. \\n\\nAlso, the user might be expecting an answer, but without the right tools, I can't provide that. So, the best response is to let them know the current situation and suggest checking a weather service for real-time updates.\\n</think>\\n\\nI currently don't have access to real-time weather data or the ability to check current weather conditions. You might want to check a weather service like Weather.com, AccuWeather, or a dedicated weather app for the latest updates on Bangalore's weather. Let me know if there's anything else I can help with!\", images=None, tool_calls=None)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "935169f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"<think>\\nOkay, the user is asking for the latest weather in Bangalore. Let me think about how to approach this.\\n\\nFirst, I need to check if there's a function available to get weather data. Looking at the tools provided, there are two functions listed, but their names and descriptions are empty. That's a problem because without knowing the actual functions, I can't use them. \\n\\nWait, maybe the functions are supposed to be part of the system, but in the given tools, they're not detailed. The user might have intended to include weather-related functions, but they weren't properly formatted. \\n\\nSince I can't use the functions as they are, I need to inform the user that I can't retrieve the latest weather data because the necessary tools aren't available. I should apologize and explain the limitation. \\n\\nAlso, the user might be expecting an answer, but without the right tools, I can't provide that. So, the best response is to let them know the current situation and suggest checking a weather service for real-time updates.\\n</think>\\n\\nI currently don't have access to real-time weather data or the ability to check current weather conditions. You might want to check a weather service like Weather.com, AccuWeather, or a dedicated weather app for the latest updates on Bangalore's weather. Let me know if there's anything else I can help with!\""
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "175586b4-acdf-4103-8039-134478a4f797",
   "metadata": {},
   "source": [
    "### Query Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12a896e0-3f56-417e-aa51-c61756048593",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_query(query):\n",
    "    \n",
    "    messages = [{'role': 'user', 'content': query}]\n",
    "    \n",
    "    response = client.chat(model = 'qwen3:1.7b', \n",
    "                                  tools = tools,\n",
    "                                  messages = messages)\n",
    "    \n",
    "    process_query = True\n",
    "    while process_query:\n",
    "        assistant_content = []\n",
    "\n",
    "        for content in response:\n",
    "            if content.type == 'text':\n",
    "                \n",
    "                print(content.text)\n",
    "                assistant_content.append(content)\n",
    "                \n",
    "                if len(response.content) == 1:\n",
    "                    process_query = False\n",
    "            \n",
    "            elif response.message.tool_calls:\n",
    "                \n",
    "                assistant_content.append(response.message.content)\n",
    "                messages.append({'role': 'assistant', 'content': assistant_content})\n",
    "                \n",
    "                tool_id = content.id\n",
    "                tool_args = content.input\n",
    "                tool_name = content.name\n",
    "                print(f\"Calling tool {tool_name} with args {tool_args}\")\n",
    "                \n",
    "                result = execute_tool(tool_name, tool_args)\n",
    "                messages.append({\"role\": \"user\", \n",
    "                                  \"content\": [\n",
    "                                      {\n",
    "                                          \"type\": \"tool_result\",\n",
    "                                          \"tool_use_id\": tool_id,\n",
    "                                          \"content\": result\n",
    "                                      }\n",
    "                                  ]\n",
    "                                })\n",
    "                response = client.messages.create(max_tokens = 2024,\n",
    "                                  model = 'claude-3-7-sonnet-20250219', \n",
    "                                  tools = tools,\n",
    "                                  messages = messages) \n",
    "                \n",
    "                if len(response.content) == 1 and response.content[0].type == \"text\":\n",
    "                    print(response.content[0].text)\n",
    "                    process_query = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2921ee7f-d2be-464b-ab7b-8db2a3c13ba9",
   "metadata": {},
   "source": [
    "### Chat Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "16979cdc-81e9-432b-ba7f-e810b52961e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat_loop():\n",
    "    print(\"Type your queries or 'quit' to exit.\")\n",
    "    while True:\n",
    "        try:\n",
    "            query = input(\"\\nQuery: \").strip()\n",
    "            if query.lower() == 'quit':\n",
    "                break\n",
    "    \n",
    "            process_query(query)\n",
    "            print(\"\\n\")\n",
    "        except Exception as e:\n",
    "            print(f\"\\nError: {str(e)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cfaf254-f22a-4951-885e-1d21fbc41ff3",
   "metadata": {},
   "source": [
    "Feel free to interact with the chatbot. Here's an example query: \n",
    "\n",
    "- Search for 2 papers on \"LLM interpretability\"\n",
    "\n",
    "To access the `papers` folder: 1) click on the `File` option on the top menu of the notebook and 2) click on `Open` and then 3) click on `L3`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39676f70-1c72-4da3-8363-da281bd5a83e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Type your queries or 'quit' to exit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:  Hi\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello! I'm here to help you search for and extract information about academic papers on arXiv. I can help you:\n",
      "\n",
      "1. Search for papers on a specific topic\n",
      "2. Get detailed information about a specific paper using its ID\n",
      "\n",
      "What would you like to know about? Please let me know if you'd like to search for papers on a particular topic or learn more about a specific paper.\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Query:  search for MCP related application in protein biology\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I'll search for papers related to MCP applications in protein biology. MCP likely refers to \"Methyl-accepting Chemotaxis Protein\" or possibly \"Multiple Chemical Programming\" in this context, but I'll search broadly to capture relevant papers.\n",
      "Calling tool search_papers with args {'topic': 'MCP protein biology application', 'max_results': 5}\n",
      "Results are saved in: papers/mcp_protein_biology_application/papers_info.json\n",
      "Let me retrieve detailed information about each of these papers to see how they relate to MCP and protein biology:\n",
      "Calling tool extract_info with args {'paper_id': '2504.08999v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2504.12757v2'}\n",
      "Calling tool extract_info with args {'paper_id': '1610.04116v1'}\n",
      "Calling tool extract_info with args {'paper_id': '2105.03617v1'}\n",
      "Calling tool extract_info with args {'paper_id': '1711.03897v2'}\n",
      "Based on the search results, I can provide you with information about MCP applications in protein biology:\n",
      "\n",
      "I notice that the search returned different meanings of \"MCP\" across the papers:\n",
      "\n",
      "1. In the first two papers (2504.08999v1 and 2504.12757v2), MCP refers to \"Model Context Protocol\" - a protocol for AI systems rather than protein biology applications.\n",
      "\n",
      "2. The third paper (1610.04116v1) discusses protein scaling theory but doesn't specifically focus on MCP in the context of proteins.\n",
      "\n",
      "3. The fourth paper (2105.03617v1) is about protein-protein interactions and docking software (MEGADOCK-GUI) but doesn't explicitly mention MCP.\n",
      "\n",
      "4. The fifth paper (1711.03897v2) discusses \"Multi Micro-Channel-Plates\" (MCPs) for photon counting detectors, which is a physics application rather than protein biology.\n",
      "\n",
      "It appears the search didn't return papers specifically about Methyl-accepting Chemotaxis Proteins (MCPs) in biology. Would you like me to perform a more specific search using terms like \"methyl-accepting chemotaxis protein\" or \"MCP bacterial chemotaxis\" to find more relevant papers about MCPs in protein biology?\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "chat_loop()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "508916f3-8fa1-4e21-bfa7-081a810bc36c",
   "metadata": {},
   "source": [
    "In the next lessons, you will take out the tool definitions to wrap them in an MCP server. Then you will create an MCP client inside the chatbot to make the chatbot MCP compatible.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d02d207b-e07d-49ff-bb03-7954aa86c167",
   "metadata": {},
   "source": [
    "## Resources\n",
    "\n",
    "[Guide on how to implement tool use](https://docs.anthropic.com/en/docs/build-with-claude/tool-use/overview#how-to-implement-tool-use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22b29b30",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace the Anthropic-based process_query with an Ollama-based version\n",
    "\n",
    "def process_query(query, model=\"llama3\"):\n",
    "    \"\"\"\n",
    "    Process a user query using a local Ollama LLM.\n",
    "    Args:\n",
    "        query (str): The user input prompt.\n",
    "        model (str): The Ollama model to use (default: 'llama3').\n",
    "    Returns:\n",
    "        str: The LLM's response.\n",
    "    \"\"\"\n",
    "    import ollama\n",
    "    response = ollama.chat(model=model, messages=[{\"role\": \"user\", \"content\": query}])\n",
    "    return response[\"message\"][\"content\"]\n",
    "\n",
    "# Example usage:\n",
    "# print(process_query(\"What is MCP?\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2730a90",
   "metadata": {},
   "source": [
    "## Ollama Function calling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04fdb8a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "import yfinance as yf \n",
    "from typing import Dict,Any, Callable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5b000ae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stock_price(symbol:str) -> float:\n",
    "    ticker = yf.Ticker(symbol)\n",
    "    price_attrs = ['regularMarketPrice', 'currentPrice', 'price']\n",
    "\n",
    "    for attr in price_attrs:\n",
    "        if attr in ticker.info and ticker.info[attr] is not None:\n",
    "            return ticker.info[attr]\n",
    "        \n",
    "    fast_info = ticker.fast_info\n",
    "    if hasattr(fast_info,'last_price') and fast_info.last_price is not None:\n",
    "        return fast_info.last_price\n",
    "    raise Exception(\"Could not find any info\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4ddf079c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "180.498"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_stock_price(\"GOOGL\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "35714451",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_stock_price_tool = {\n",
    "    'type': 'function',\n",
    "    'function': {\n",
    "        'name': 'get_stock_price',\n",
    "        'description': 'Get the current stock price for any symbol',\n",
    "        'parameters': {\n",
    "            'type': 'object',\n",
    "            'required': ['symbol'],\n",
    "            'properties': {\n",
    "                'symbol': {'type': 'string', 'description': 'The stock symbol (e.g., AAPL, GOOGL)'},\n",
    "            },\n",
    "        },\n",
    "    },\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1f71fd11",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prompt: What is the current stock price of Apple?\n"
     ]
    }
   ],
   "source": [
    "prompt = 'What is the current stock price of Apple?'\n",
    "print('Prompt:', prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "191f90f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "available_functions:Dict[str,Callable] = {\n",
    "    'get_stock_price' :get_stock_price\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bdabb2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = ollama.chat(\n",
    "    'qwen3:1.7b',\n",
    "    messages=[{'role':'user', 'content':prompt}],\n",
    "    tools = [get_stock_price]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25f9ee83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatResponse(model='qwen3:1.7b', created_at='2025-07-14T16:43:20.1356194Z', done=True, done_reason='stop', total_duration=11528222200, load_duration=7940143600, prompt_eval_count=140, prompt_eval_duration=1089402100, eval_count=107, eval_duration=2481158100, message=Message(role='assistant', content='<think>\\nOkay, the user is asking for the current stock price of Apple. Let me check the tools available. There\\'s a function called get_stock_price which requires a symbol parameter. Apple\\'s stock symbol is AAPL. So I need to call this function with the symbol \"AAPL\". I should make sure the parameters are correctly formatted as JSON within the tool_call tags. Let me structure the response properly.\\n</think>\\n\\n', images=None, tool_calls=[ToolCall(function=Function(name='get_stock_price', arguments={'symbol': 'AAPL'}))]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f001c173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Calling function: get_stock_price\n",
      "Arguments: {'symbol': 'AAPL'}\n",
      "Function output: 209.05\n"
     ]
    }
   ],
   "source": [
    "if response.message.tool_calls:\n",
    "    for tool in response.message.tool_calls:\n",
    "        if function_to_call := available_functions.get(tool.function.name):\n",
    "            print('Calling function:', tool.function.name)\n",
    "            print('Arguments:', tool.function.arguments)\n",
    "            print('Function output:', function_to_call(**tool.function.arguments))\n",
    "        else:\n",
    "            print('Function', tool.function.name, 'not found')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9980c5ae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Model(model='gemma3:4b', modified_at=datetime.datetime(2025, 6, 18, 0, 35, 9, 741285, tzinfo=TzInfo(+05:30)), digest='a2af6cc3eb7fa8be8504abaf9b04e88f17a119ec3f04a3addf55f92841195f5a', size=3338801804, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='4.3B', quantization_level='Q4_K_M')),\n",
       " Model(model='qwen3:1.7b', modified_at=datetime.datetime(2025, 6, 13, 0, 0, 55, 230752, tzinfo=TzInfo(+05:30)), digest='8f68893c685c3ddff2aa3fffce2aa60a30bb2da65ca488b61fff134a4d1730e7', size=1359293444, details=ModelDetails(parent_model='', format='gguf', family='qwen3', families=['qwen3'], parameter_size='2.0B', quantization_level='Q4_K_M')),\n",
       " Model(model='gemma3:1b', modified_at=datetime.datetime(2025, 5, 10, 11, 10, 25, 297843, tzinfo=TzInfo(+05:30)), digest='8648f39daa8fbf5b18c7b4e6a8fb4990c692751d49917417b8842ca5758e7ffc', size=815319791, details=ModelDetails(parent_model='', format='gguf', family='gemma3', families=['gemma3'], parameter_size='999.89M', quantization_level='Q4_K_M'))]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import ollama\n",
    "ollama.list().models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "df499000",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, the user is asking for the stock price of Ford. Let me check the tools available. There's a function called get_stock_price that takes a symbol parameter. Ford's stock symbol is F. So I need to call this function with symbol \"F\". Let me make sure I have the correct symbol. Yes, Ford is listed as F on the stock market. Alright, I'll use that function to retrieve the current price.\n",
      "</think>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from ollama import chat\n",
    "from ollama import ChatResponse\n",
    "\n",
    "response: ChatResponse = chat(model='qwen3:1.7b', messages=[\n",
    "  {\n",
    "    'role': 'user',\n",
    "    'content': 'what is the stock price of Ford',\n",
    "  }\n",
    "],\n",
    "tools=[get_stock_price_tool])# or access fields directly from the response object\n",
    "print(response.message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "023cf797",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ToolCall(function=Function(name='get_stock_price', arguments={'symbol': 'F'}))]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.message.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "90a04299",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "assistant\n",
      "<think>\n",
      "Okay, the user is asking for the stock price of Ford. Let me check the tools available. There's a function called get_stock_price that takes a symbol parameter. Ford's stock symbol is F. So I need to call this function with symbol \"F\". Let me make sure I have the correct symbol. Yes, Ford is listed as F on the stock market. Alright, I'll use that function to retrieve the current price.\n",
      "</think>\n",
      "\n",
      "\n",
      "None\n",
      "[ToolCall(function=Function(name='get_stock_price', arguments={'symbol': 'F'}))]\n",
      "('tool_calls', [ToolCall(function=Function(name='get_stock_price', arguments={'symbol': 'F'}))])\n"
     ]
    }
   ],
   "source": [
    "for content in response.message:\n",
    "    print(content[1])\n",
    "    if content[0] == 'tool_calls':\n",
    "        print(content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "projects",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
